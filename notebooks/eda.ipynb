{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdb_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m QUERY\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "# Models and metrics\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "import xgboost as xgb\n",
    "from hyperopt import hp\n",
    "import vectorbtpro as vbt\n",
    "\n",
    "# Classification metrics\n",
    "from sklearn.metrics import classification_report, precision_recall_curve, auc, r2_score\n",
    "from sklearn.calibration import calibration_curve, CalibrationDisplay\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Suppress all warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Other imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "from utils.db_utils import QUERY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_features = QUERY('SELECT * FROM (DESCRIBE market_data.ml_features)')['column_name'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns we need to drop before training the model\n",
    "forward_returns_cols = [col for col in ml_features if 'forward_returns' in col]\n",
    "\n",
    "non_numeric_cols = [\n",
    "    'asset_id_base','asset_id_base_x','asset_id_base_y', \n",
    "    'asset_id_quote','asset_id_quote_x', 'asset_id_quote_y', \n",
    "    'exchange_id','exchange_id_x','exchange_id_y', \n",
    "    'day_of_week', 'month', 'symbol_id'\n",
    "]\n",
    "\n",
    "other_cols = [\n",
    "    'open_spot', 'high_spot', 'low_spot', 'close_spot', 'volume_spot', 'trades_spot',\n",
    "    'open_futures', 'high_futures', 'low_futures', 'close_futures', 'volume_futures', 'trades_futures',\n",
    "    'time_period_end'\n",
    "]\n",
    "\n",
    "num_cols = [col for col in ml_features if 'num' in col and 'rz' not in col and 'zscore' not in col and 'percentile' not in col]\n",
    "\n",
    "dollar_cols = [col for col in ml_features if 'dollar' in col and 'rz' not in col and 'zscore' not in col and 'percentile' not in col]\n",
    "\n",
    "delta_cols = [col for col in ml_features if 'delta' in col and 'rz' not in col and 'zscore' not in col and 'percentile' not in col]\n",
    "\n",
    "other = [col for col in ml_features if '10th_percentile' in col or '90th_percentile' in col]\n",
    "\n",
    "cols_to_drop = (\n",
    "    forward_returns_cols +\n",
    "    non_numeric_cols +\n",
    "    other_cols +\n",
    "    num_cols +\n",
    "    dollar_cols +\n",
    "    delta_cols +\n",
    "    other\n",
    ")\n",
    "\n",
    "# Columns to include in the model\n",
    "returns_cols = [col for col in ml_features if ('spot_returns' in col or 'futures_returns' in col) and 'cs_' not in col]\n",
    "returns_cs_cols = [col for col in ml_features if ('spot_returns' in col or 'futures_returns' in col) and 'cs_' in col and 'kurtosis' not in col]\n",
    "\n",
    "alpha_beta_cols = [col for col in ml_features if ('alpha' in col or 'beta' in col) and 'cs_' not in col]\n",
    "alpha_beta_cs_cols = [col for col in ml_features if ('alpha' in col or 'beta' in col) and 'cs_' in col and 'kurtosis' not in col]\n",
    "\n",
    "basis_pct_cols = [col for col in ml_features if 'basis_pct' in col and 'cs_' not in col]\n",
    "basis_pct_cs_cols = [col for col in ml_features if 'basis_pct' in col and 'cs_' in col and 'kurtosis' not in col]\n",
    "\n",
    "trade_imbalance_cols = [col for col in ml_features if 'trade_imbalance' in col and 'cs_' not in col]\n",
    "trade_imbalance_cs_cols = [col for col in ml_features if 'trade_imbalance' in col and 'cs_' in col and 'kurtosis' not in col]\n",
    "\n",
    "valid_cols = (\n",
    "    returns_cols +\n",
    "    returns_cs_cols +\n",
    "    alpha_beta_cols +\n",
    "    alpha_beta_cs_cols +\n",
    "    basis_pct_cols +\n",
    "    basis_pct_cs_cols +\n",
    "    trade_imbalance_cols +\n",
    "    trade_imbalance_cs_cols\n",
    ")\n",
    "\n",
    "rz_cols = [col for col in ml_features if ('rz' in col or 'zscore' in col or ('percentile' in col and '10th_percentile' not in col and '90th_percentile' not in col) or col in valid_cols) and 'forward_returns' not in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_hyperparameter_tuning(X, y, param_space, max_evals=5, direction = 'long'):\n",
    "    from hyperopt import fmin, tpe, Trials\n",
    "\n",
    "    def objective(params):\n",
    "      params['max_depth'] = int(params['max_depth'])  # Ensure max_depth is an integer\n",
    "      params['n_estimators'] = int(params['n_estimators'])\n",
    "      params['min_child_weight'] = int(params['min_child_weight'])  # Ensure min_child_weight is an integer\n",
    "      \n",
    "      # Split the data into training and validation sets (e.g., 80% train, 20% validation)\n",
    "      train_end_date = X['time_period_end'].quantile(0.8)\n",
    "      X_train = X[X['time_period_end'] <= train_end_date]\n",
    "      X_val = X[X['time_period_end'] > train_end_date]\n",
    "      if direction == 'long':\n",
    "        y_train = (X_train['forward_returns_7'] > 0).astype(int)\n",
    "        y_val = (X_val['forward_returns_7'] > 0).astype(int)\n",
    "      else:\n",
    "        y_train = (X_train['futures_forward_returns_7'] < 0).astype(int)\n",
    "        y_val = (X_val['futures_forward_returns_7'] < 0).astype(int)\n",
    "\n",
    "      print(f'Train date range: {X_train[\"time_period_end\"].min()}-{X_train[\"time_period_end\"].max()}')\n",
    "      print(f'Validation date range: {X_val[\"time_period_end\"].min()}-{X_val[\"time_period_end\"].max()}')\n",
    "      print()\n",
    "\n",
    "      # Fit the XGBoost model with the given hyperparameters\n",
    "      model = xgb.XGBClassifier(**params)\n",
    "      model.fit(X_train.drop(cols_to_drop, axis=1, errors='ignore'), y_train, eval_set=[(X_val.drop(cols_to_drop, axis=1, errors='ignore'), y_val)])\n",
    "\n",
    "      # Make predictions on the validation set\n",
    "      y_pred_proba = model.predict_proba(X_val.drop(cols_to_drop, axis=1, errors='ignore'))[:, 1]\n",
    "      y_pred = (y_pred_proba >= 0.7).astype(int)\n",
    "      f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "      # Calculate Sortino-like metric of 7-day forward returns\n",
    "      pred_mask = (y_pred == 1)\n",
    "      forward_returns = X_val['forward_returns_7']\n",
    "      expectancy = np.mean(forward_returns[pred_mask])\n",
    "      std_dev_neg = np.std(forward_returns[pred_mask & (forward_returns < 0)])\n",
    "      sortino_like_metric = (expectancy / std_dev_neg) if std_dev_neg != 0 else 0\n",
    "      market_returns = X_val['forward_returns_7']\n",
    "      market_expectancy = np.mean(market_returns)\n",
    "      market_std_dev_neg = np.std(market_returns[market_returns < 0])\n",
    "      \n",
    "      # Calculate classification metrics\n",
    "      print(f'Hyperparameters: {params}')\n",
    "      print()\n",
    "      print(classification_report(y_val, y_pred))\n",
    "      print()\n",
    "      print(f'Expectancy: {expectancy}, Market Expectancy: {market_expectancy}')\n",
    "      print(f'Std Dev Negative: {std_dev_neg}, Market Std Dev Negative: {market_std_dev_neg}')\n",
    "      print(f'Sortino-Like: {sortino_like_metric}, Market Sortino-Like: {market_expectancy / market_std_dev_neg if market_std_dev_neg != 0 else 0}')\n",
    "      print()\n",
    "\n",
    "      # Calculate the loss (negative Sortino-like metric)\n",
    "      optimization_metric = -f1\n",
    "      print(f'Optimization Metric: {optimization_metric}')\n",
    "      print('=' * 80)\n",
    "      return {'loss': optimization_metric, 'status': 'ok'}\n",
    "\n",
    "    trials = Trials()\n",
    "    best = fmin(objective, param_space, algo=tpe.suggest, max_evals=max_evals, trials=trials)\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T06:44:59.800638Z",
     "start_time": "2025-05-24T06:44:59.787892Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(min_year, max_year, is_reg, model_type, direction='long'):\n",
    "    for year in range(min_year, max_year + 1):\n",
    "        # Train XGBoost model for each month\n",
    "        for month in range(1, 13):\n",
    "            # if year < 2022 or (year == 2022 and month < 6):\n",
    "            #     continue\n",
    "            \n",
    "            if direction == 'long':\n",
    "                query = f\"\"\"\n",
    "                SELECT *\n",
    "                FROM market_data.ml_features\n",
    "                WHERE\n",
    "                    date_part('year', time_period_end) < {year} OR\n",
    "                    (date_part('year', time_period_end) = {year} AND\n",
    "                     date_part('month', time_period_end) <= {month})\n",
    "                \"\"\"\n",
    "            else:\n",
    "                query = f\"\"\"\n",
    "                SELECT *\n",
    "                FROM market_data.ml_features\n",
    "                WHERE\n",
    "                    date_part('year', time_period_end) < {year} OR\n",
    "                    (date_part('year', time_period_end) = {year} AND\n",
    "                     date_part('month', time_period_end) <= {month}) AND\n",
    "                     close_futures IS NOT NULL -- Ensure futures data is available for the model to train\n",
    "                \"\"\"\n",
    "\n",
    "            data_train = QUERY(query)\n",
    "            data_train['symbol_id'] = (\n",
    "                data_train['asset_id_base'].str.upper() +\n",
    "                '_' +\n",
    "                data_train['asset_id_quote'].str.upper() +\n",
    "                '_' +\n",
    "                data_train['exchange_id'].str.upper()\n",
    "            ).astype('category')\n",
    "            data_train['day_of_week'] = data_train['day_of_week'].astype('category')\n",
    "            data_train['month'] = data_train['month'].astype('category')\n",
    "\n",
    "            max_train_date = pd.to_datetime(data_train['time_period_end'].dt.date.max())\n",
    "            min_train_date = pd.to_datetime(max_train_date - pd.Timedelta(days = 365 * 2))\n",
    "\n",
    "            # Test data is all data in the next month\n",
    "            next_month = month + 1\n",
    "            if next_month == 13:\n",
    "                next_year = year + 1\n",
    "                next_month = 1\n",
    "            else:\n",
    "                next_year = year\n",
    "\n",
    "            if direction == 'long':\n",
    "                query = f\"\"\"\n",
    "                SELECT *\n",
    "                FROM market_data.ml_features\n",
    "                WHERE\n",
    "                    time_period_end > '{max_train_date}' AND\n",
    "                    date_part('year', time_period_end) = {next_year} AND\n",
    "                    date_part('month', time_period_end) <= {next_month}\n",
    "                \"\"\"\n",
    "            else:\n",
    "                query = f\"\"\"\n",
    "                SELECT *\n",
    "                FROM market_data.ml_features\n",
    "                WHERE\n",
    "                    time_period_end > '{max_train_date}' AND\n",
    "                    date_part('year', time_period_end) = {next_year} AND\n",
    "                    date_part('month', time_period_end) <= {next_month} AND\n",
    "                    close_futures IS NOT NULL -- Ensure futures data is available for the model to test\n",
    "                \"\"\"\n",
    "            data_test = QUERY(query)\n",
    "            data_test['symbol_id'] = (\n",
    "                data_test['asset_id_base'].str.upper() +\n",
    "                '_' +\n",
    "                data_test['asset_id_quote'].str.upper() +\n",
    "                '_' +\n",
    "                data_test['exchange_id'].str.upper()\n",
    "            ).astype('category')\n",
    "            data_test['day_of_week'] = data_test['day_of_week'].astype('category')\n",
    "            data_test['month'] = data_test['month'].astype('category')\n",
    "\n",
    "            data_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "            data_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "            # Sort data by symbol_id and time_period_end\n",
    "            data_train = data_train.sort_values(by=['symbol_id', 'time_period_end'])\n",
    "            data_test = data_test.sort_values(by=['symbol_id', 'time_period_end'])\n",
    "\n",
    "            if direction == 'long':\n",
    "                # Filter out data with nan forward returns\n",
    "                data_train = data_train.dropna(subset=['forward_returns_7'])\n",
    "                data_test = data_test.dropna(subset=['forward_returns_7'])\n",
    "            else:\n",
    "                # Filter out data with nan futures forward returns\n",
    "                data_train = data_train.dropna(subset=['futures_forward_returns_7'])\n",
    "                data_test = data_test.dropna(subset=['futures_forward_returns_7'])\n",
    "\n",
    "            # Filter out training data older than 2 years from the max train date\n",
    "            filter_train = (\n",
    "                data_train['time_period_end'] >= min_train_date\n",
    "            )\n",
    "            filter_test = (\n",
    "            )\n",
    "            # data_train = data_train[filter_train]\n",
    "            # data_test = data_test[filter_test]\n",
    "\n",
    "            data_train['symbol_id'] = data_train['symbol_id'].astype('category')\n",
    "            data_test['symbol_id'] = data_test['symbol_id'].astype('category')\n",
    "\n",
    "            if data_train.empty or data_test.empty:\n",
    "                continue\n",
    "\n",
    "            X_train = data_train\n",
    "            X_test = data_test\n",
    "\n",
    "            # Ensure no data leakage\n",
    "            assert X_train['time_period_end'].max() < X_test['time_period_end'].min(), 'Data leakage detected'\n",
    "\n",
    "            # Split data into features and target\n",
    "            if is_reg:\n",
    "                y_train = X_train['forward_returns_7'].abs()\n",
    "                y_test = X_test['forward_returns_7'].abs()\n",
    "            else:\n",
    "                if direction == 'long':\n",
    "                    y_train = (X_train['forward_returns_7'] > 0).astype(int)\n",
    "                    y_test = (X_test['forward_returns_7'] > 0).astype(int)\n",
    "                else:\n",
    "                    y_train = (X_train['futures_forward_returns_7'] < 0).astype(int)\n",
    "                    y_test = (X_test['futures_forward_returns_7'] < 0).astype(int)\n",
    "\n",
    "            print()\n",
    "            print(f'Train Date Range: {X_train[\"time_period_end\"].min()} - {X_train[\"time_period_end\"].max()}')\n",
    "            print(f'Number of observations (Train): {X_train.shape[0]}')\n",
    "            print()\n",
    "\n",
    "            print(f'Test Date Range: {X_test[\"time_period_end\"].min()} - {X_test[\"time_period_end\"].max()}')\n",
    "            print(f'Number of observations (Test): {X_test.shape[0]}')\n",
    "            print()\n",
    "\n",
    "            # Ensure no data leakage\n",
    "            data_leakage_indicator = (\n",
    "                (X_train['time_period_end'].max() >= X_test['time_period_end'].min())\n",
    "            )\n",
    "            assert not data_leakage_indicator, 'Data leakage detected'\n",
    "\n",
    "            if model_type != 'xgb':\n",
    "                # Define the model\n",
    "                ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "                # OHE train data\n",
    "                encoded_data = ohe.fit_transform(X_train[['symbol_id', 'day_of_week', 'month']])\n",
    "                encoded_cols = ohe.get_feature_names_out(['symbol_id', 'day_of_week', 'month'])\n",
    "                encoded_df = pd.DataFrame(encoded_data, columns = encoded_cols, index = X_train.index)\n",
    "                X_train = pd.concat([X_train[rz_cols], encoded_df], axis = 1)\n",
    "\n",
    "                # OHE test data\n",
    "                encoded_data = ohe.transform(X_test[['symbol_id', 'day_of_week', 'month']])\n",
    "                encoded_cols = ohe.get_feature_names_out(['symbol_id', 'day_of_week', 'month'])\n",
    "                encoded_df = pd.DataFrame(encoded_data, columns=encoded_cols, index = X_test.index)\n",
    "                X_test_ = pd.concat([X_test_[rz_cols], encoded_df], axis = 1)\n",
    "\n",
    "            # Winsorize training and test data\n",
    "            # Ensure no NaN values in the training and test data if not using XGBoost\n",
    "            if model_type != 'xgb':\n",
    "                p001 = X_train.quantile(0.001)\n",
    "                p999 = X_train.quantile(0.999)\n",
    "                X_train = X_train.clip(lower=p001, upper=p999, axis=1)\n",
    "                # Winsorize test data using train percentiles\n",
    "                X_test_ = X_test_.clip(lower=p001, upper=p999, axis=1)\n",
    "\n",
    "                X_train = X_train.fillna(0)\n",
    "                X_test_ = X_test_.fillna(0)\n",
    "            \n",
    "            # Define the model\n",
    "            if model_type == 'lr':\n",
    "                model = LogisticRegression(\n",
    "                    penalty='elasticnet',\n",
    "                    solver='saga',\n",
    "                    l1_ratio=0.5,\n",
    "                    class_weight='balanced',\n",
    "                    C = 0.1,\n",
    "                    random_state=9+10,\n",
    "                    n_jobs=-1,\n",
    "                )\n",
    "            elif model_type == 'nn':\n",
    "                model = MLPClassifier(\n",
    "                    hidden_layer_sizes=(100,100), \n",
    "                    alpha = 10, \n",
    "                    verbose=True, \n",
    "                    max_iter = 100, \n",
    "                    random_state = 9+10, \n",
    "                    tol = 0.01, \n",
    "                    n_iter_no_change=1\n",
    "                )\n",
    "            elif model_type == 'xgb':\n",
    "                param_space = {\n",
    "                    'objective': 'binary:logistic',\n",
    "                    'n_estimators': 200,\n",
    "                    'max_depth': 12,\n",
    "                    'min_child_weight': 5,\n",
    "                    'reg_lambda': 10,\n",
    "                    'random_state': 9+10,\n",
    "                    'class_weight': 'balanced',\n",
    "                    'njobs': -1\n",
    "                }\n",
    "                model = xgb.XGBClassifier(**param_space)\n",
    "            \n",
    "            if direction == 'long':\n",
    "                y_train = (X_train['forward_returns_7'] > 0).astype(int)\n",
    "                y_test = (X_test['forward_returns_7'] > 0).astype(int)\n",
    "            else:\n",
    "                y_train_ = (X_train['futures_forward_returns_7'] < 0).astype(int)\n",
    "                y_test = (X_test['futures_forward_returns_7'] < 0).astype(int)\n",
    "\n",
    "            futures_forward_returns_cols = [col for col in X_train.columns if 'forward_returns' in col]\n",
    "\n",
    "            X_train = X_train.drop(columns=cols_to_drop + futures_forward_returns_cols, errors='ignore', axis=1)\n",
    "            X_test_ = X_test.drop(columns=cols_to_drop + futures_forward_returns_cols, errors='ignore', axis=1)\n",
    "\n",
    "            if model_type != 'xgb':\n",
    "                model.fit(X_train, y_train)\n",
    "            else:\n",
    "                model.fit(\n",
    "                    X_train, \n",
    "                    y_train\n",
    "                )\n",
    "\n",
    "            y_pred_proba = model.predict_proba(X_test_)[:, 1]\n",
    "            y_pred = (y_pred_proba >= 0.7).astype(int)\n",
    "\n",
    "            X_test['y_true'] = y_test\n",
    "            X_test['y_pred'] = y_pred\n",
    "            X_test['y_pred_proba'] = y_pred_proba\n",
    "\n",
    "            print('Class Distribution:')\n",
    "            print(X_test['y_true'].value_counts(normalize = True))\n",
    "            print()\n",
    "\n",
    "            trade_side = np.where(\n",
    "                y_pred == 1, 1, 0\n",
    "            )\n",
    "            if direction == 'short':\n",
    "                trade_side = np.where(y_pred == 1, -1, 0)\n",
    "                trade_pnl = trade_side * X_test['futures_forward_returns_7'].values\n",
    "                trades_mask = trade_side == -1\n",
    "                expectancy = trade_pnl[trades_mask].mean()\n",
    "                std_neg = trade_pnl[trades_mask & (trade_pnl < 0)].std()\n",
    "                sortino_like = expectancy / std_neg if std_neg != 0 else 0\n",
    "                hit_rate = (trade_pnl[trades_mask] > 0).mean()\n",
    "            else:\n",
    "                trade_side = np.where(y_pred == 1, 1, 0)\n",
    "                trade_pnl = trade_side * X_test['forward_returns_7'].values\n",
    "                trades_mask = trade_side == 1\n",
    "                expectancy = trade_pnl[trades_mask].mean()\n",
    "                std_neg = trade_pnl[trades_mask & (trade_pnl < 0)].std()\n",
    "                sortino_like = expectancy / std_neg if std_neg != 0 else 0\n",
    "                hit_rate = (trade_pnl[trades_mask] > 0).mean()\n",
    "\n",
    "            if direction == 'long':\n",
    "                # Market Performance\n",
    "                market_expectancy = X_test['forward_returns_7'].mean()\n",
    "                market_std_neg = X_test['forward_returns_7'][X_test['forward_returns_7'] < 0].std()\n",
    "                market_sortino_like = market_expectancy / market_std_neg if market_std_neg != 0 else 0\n",
    "                market_hit_rate = (X_test['forward_returns_7'] > 0).mean()\n",
    "            else:\n",
    "                # Market Performance\n",
    "                market_expectancy = -X_test['futures_forward_returns_7'].mean()\n",
    "                market_std_neg = X_test['futures_forward_returns_7'][X_test['futures_forward_returns_7'] > 0].std()\n",
    "                market_sortino_like = market_expectancy / market_std_neg if market_std_neg != 0 else 0\n",
    "                market_hit_rate = (X_test['futures_forward_returns_7'] < 0).mean()\n",
    "                \n",
    "            print(f'Expectancy: {expectancy:.3f}, Market Expectancy: {market_expectancy:.3f}')\n",
    "            print(f'Std Negative Returns: {std_neg:.3f}, Market Std Negative Returns: {market_std_neg:.3f}')\n",
    "            print(f'Sortino-Like: {sortino_like:.3f}, Market Sortino-Like: {market_sortino_like:.3f}')\n",
    "            print(f'Hit Rate: {hit_rate:.3f}, Market Hit Rate: {market_hit_rate:.3f}')\n",
    "            print()\n",
    "\n",
    "            # Classification Report\n",
    "            print('Classification Report:')\n",
    "            print(classification_report(X_test['y_true'], X_test['y_pred']))\n",
    "            print()\n",
    "\n",
    "            # Calibration Curve\n",
    "            disp = CalibrationDisplay.from_predictions(y_test, y_pred_proba)\n",
    "            plt.show()\n",
    "\n",
    "            precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "            pr_auc = auc(recall, precision)\n",
    "\n",
    "            if model_type == 'lr':\n",
    "                # Subplots 2 columns, 1 row\n",
    "                fig, ax = plt.subplots(1, 2, figsize=(15, 7))\n",
    "\n",
    "                # Top 50 most important positive features\n",
    "                top_n_pos = 50\n",
    "                feature_importances = pd.Series(model.coef_[0], index=X_test_.columns)\n",
    "                feature_importances = feature_importances.sort_values().tail(top_n_pos)\n",
    "                feature_importances.plot(kind='barh', title='Top 50 Most Important Features', ax=ax[0])\n",
    "\n",
    "                # Top 50 most important negative features\n",
    "                top_n_neg = 50\n",
    "                feature_importances_neg = pd.Series(model.coef_[0], index=X_test_.columns)\n",
    "                feature_importances_neg = feature_importances_neg.sort_values().head(top_n_neg)\n",
    "                feature_importances_neg.plot(kind='barh', title='Top 50 Most Important Negative Features', ax=ax[1])\n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "            elif model_type == 'xgb':\n",
    "                try:\n",
    "                    fig, ax = plt.subplots(figsize=(15, 7))\n",
    "                    # Plot feature importance\n",
    "                    xgb.plot_importance(model, max_num_features=50, importance_type='gain', ax=ax, title='Top 50 Most Important Features')\n",
    "                    plt.show()\n",
    "                except Exception as e:\n",
    "                    print(f'Error plotting feature importance: {e}')\n",
    "                    print()\n",
    "            \n",
    "            # Delete old data from memory\n",
    "            del X_train\n",
    "            del X_test\n",
    "            del data_train\n",
    "            del data_test\n",
    "\n",
    "            if model_type == 'lr':\n",
    "                # Save the model\n",
    "                model_path = f'/Users/louisspencer/Desktop/Trading-Bot/data/pretrained_models/classification/lr_model_{next_year}_{next_month}.pkl'\n",
    "                joblib.dump(model, model_path)\n",
    "            elif model_type == 'nn':\n",
    "                # Save the model\n",
    "                model_path = f'/Users/louisspencer/Desktop/Trading-Bot/data/pretrained_models/classification/nn_model_{next_year}_{next_month}.pkl'\n",
    "                joblib.dump(model, model_path)\n",
    "            elif model_type == 'xgb':\n",
    "                \n",
    "                if direction == 'long':\n",
    "                    model_path = f'/Users/louisspencer/Desktop/Trading-Bot/data/pretrained_models/classification/xgb_long_model_{next_year}_{next_month}.pkl'\n",
    "                else:\n",
    "                    model_path = f'/Users/louisspencer/Desktop/Trading-Bot/data/pretrained_models/classification/xgb_short_model_{next_year}_{next_month}.pkl'\n",
    "                \n",
    "                # Save the model\n",
    "                joblib.dump(model, model_path)\n",
    "\n",
    "            if model_type != 'xgb':\n",
    "                # Save the OneHotEncoder to have the same encoding for backtesting\n",
    "                ohe_path = f'/Users/louisspencer/Desktop/Trading-Bot/data/pretrained_models/classification/ohe_{next_year}_{next_month}.pkl'\n",
    "                joblib.dump(ohe, ohe_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T06:45:00.030187Z",
     "start_time": "2025-05-24T06:44:59.820737Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m(\u001b[38;5;241m2020\u001b[39m, \u001b[38;5;241m2025\u001b[39m, is_reg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, model_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxgb\u001b[39m\u001b[38;5;124m'\u001b[39m, direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshort\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_model' is not defined"
     ]
    }
   ],
   "source": [
    "train_model(2020, 2025, is_reg=False, model_type='xgb', direction='short')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance_metrics(min_year, max_year, is_reg, model_type, direction='long'):\n",
    "    performance_metrics = []\n",
    "    init_cash = 10_000\n",
    "    for year in range(min_year, max_year + 1):\n",
    "        # Train XGBoost model for each month\n",
    "        for month in range(1, 13):\n",
    "            if year == 2018 and month < 11:\n",
    "                continue\n",
    "\n",
    "            if direction == 'long':\n",
    "                data_train = QUERY(\n",
    "                    f\"\"\"\n",
    "                    SELECT *\n",
    "                    FROM market_data.ml_features\n",
    "                    WHERE\n",
    "                        date_part('year', time_period_end) < {year} OR\n",
    "                        (date_part('year', time_period_end) = {year} AND\n",
    "                        date_part('month', time_period_end) <= {month})\n",
    "                    \"\"\"\n",
    "                )\n",
    "            else:\n",
    "                data_train = QUERY(\n",
    "                    f\"\"\"\n",
    "                    SELECT *\n",
    "                    FROM market_data.ml_features\n",
    "                    WHERE\n",
    "                        date_part('year', time_period_end) < {year} OR\n",
    "                        (date_part('year', time_period_end) = {year} AND\n",
    "                        date_part('month', time_period_end) <= {month}) AND\n",
    "                        close_futures IS NOT NULL -- Ensure futures data is available for the model to train\n",
    "                    \"\"\"\n",
    "                )\n",
    "            data_train['symbol_id'] = (\n",
    "                data_train['asset_id_base'].str.upper() +\n",
    "                '_' +\n",
    "                data_train['asset_id_quote'].str.upper() +\n",
    "                '_' +\n",
    "                data_train['exchange_id'].str.upper()\n",
    "            ).astype('category')\n",
    "            data_train['day_of_week'] = data_train['day_of_week'].astype('category')\n",
    "            data_train['month'] = data_train['month'].astype('category')\n",
    "\n",
    "            max_train_date = pd.to_datetime(data_train['time_period_end'].dt.date.max())\n",
    "            min_train_date = pd.to_datetime(max_train_date - pd.Timedelta(days = 365 * 2))\n",
    "\n",
    "            # Test data is all data in the next month\n",
    "            next_month = month + 1\n",
    "            if next_month == 13:\n",
    "                next_year = year + 1\n",
    "                next_month = 1\n",
    "            else:\n",
    "                next_year = year\n",
    "\n",
    "            if direction == 'long':\n",
    "                data_test = QUERY(\n",
    "                    f\"\"\"\n",
    "                    SELECT *\n",
    "                    FROM market_data.ml_features\n",
    "                    WHERE\n",
    "                        time_period_end > '{max_train_date}' AND\n",
    "                        date_part('year', time_period_end) = {next_year} AND\n",
    "                        date_part('month', time_period_end) <= {next_month}\n",
    "                    \"\"\"\n",
    "                )\n",
    "            else:\n",
    "                data_test = QUERY(\n",
    "                    f\"\"\"\n",
    "                    SELECT *\n",
    "                    FROM market_data.ml_features\n",
    "                    WHERE\n",
    "                        time_period_end > '{max_train_date}' AND\n",
    "                        date_part('year', time_period_end) = {next_year} AND\n",
    "                        date_part('month', time_period_end) <= {next_month} AND\n",
    "                        close_futures IS NOT NULL -- Ensure futures data is available for the model to test\n",
    "                    \"\"\"\n",
    "                )\n",
    "            data_test['symbol_id'] = (\n",
    "                data_test['asset_id_base'].str.upper() +\n",
    "                '_' +\n",
    "                data_test['asset_id_quote'].str.upper() +\n",
    "                '_' +\n",
    "                data_test['exchange_id'].str.upper()\n",
    "            ).astype('category')\n",
    "            data_test['day_of_week'] = data_test['day_of_week'].astype('category')\n",
    "            data_test['month'] = data_test['month'].astype('category')\n",
    "\n",
    "            data_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "            data_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "            # Filter out data with nan trade_returns_h7\n",
    "            data_train = data_train.dropna(subset = ['forward_returns_7'])\n",
    "            data_test = data_test.dropna(subset = ['forward_returns_7'])\n",
    "\n",
    "            # Filter out training data older than 2 years from the max train date\n",
    "            filter_train = (\n",
    "                data_train['time_period_end'] >= min_train_date\n",
    "            )\n",
    "            filter_test = (\n",
    "            )\n",
    "            data_train = data_train[filter_train]\n",
    "\n",
    "            if data_train.empty or data_test.empty:\n",
    "                continue\n",
    "\n",
    "            X_train = data_train\n",
    "            X_test = data_test\n",
    "\n",
    "            # Split data into features and target\n",
    "            if is_reg:\n",
    "                y_train = X_train['forward_returns_7'].abs()\n",
    "                y_test = X_test['forward_returns_7'].abs()\n",
    "            else:\n",
    "                if direction == 'long':\n",
    "                    y_train = (X_train['forward_returns_7'] > 0).astype(int)\n",
    "                    y_test = (X_test['forward_returns_7'] > 0).astype(int)\n",
    "                else:\n",
    "                    y_train = (X_train['futures_forward_returns_7'] < 0).astype(int)\n",
    "                    y_test = (X_test['futures_forward_returns_7'] < 0).astype(int)\n",
    "\n",
    "            print()\n",
    "            print(f'Train Date Range: {X_train[\"time_period_end\"].min()} - {X_train[\"time_period_end\"].max()}')\n",
    "            print(f'Number of observations (Train): {X_train.shape[0]}')\n",
    "            print()\n",
    "\n",
    "            print(f'Test Date Range: {X_test[\"time_period_end\"].min()} - {X_test[\"time_period_end\"].max()}')\n",
    "            print(f'Number of observations (Test): {X_test.shape[0]}')\n",
    "            print()\n",
    "\n",
    "            # Ensure no data leakage\n",
    "            data_leakage_indicator = (\n",
    "                (X_train['time_period_end'].max() > X_test['time_period_end'].min())\n",
    "            )\n",
    "            assert not data_leakage_indicator, 'Data leakage detected'\n",
    "\n",
    "            X_train = X_train.drop(columns=cols_to_drop)\n",
    "            X_test_ = X_test.drop(columns=cols_to_drop)\n",
    "\n",
    "            if model_type != 'xgb':\n",
    "                # Define the model\n",
    "                ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "                # OHE train data\n",
    "                encoded_data = ohe.fit_transform(X_train[['symbol_id', 'day_of_week', 'month']])\n",
    "                encoded_cols = ohe.get_feature_names_out(['symbol_id', 'day_of_week', 'month'])\n",
    "                encoded_df = pd.DataFrame(encoded_data, columns = encoded_cols, index = X_train.index)\n",
    "                X_train = pd.concat([X_train[rz_cols], encoded_df], axis = 1)\n",
    "\n",
    "                # OHE test data\n",
    "                encoded_data = ohe.transform(X_test[['symbol_id', 'day_of_week', 'month']])\n",
    "                encoded_cols = ohe.get_feature_names_out(['symbol_id', 'day_of_week', 'month'])\n",
    "                encoded_df = pd.DataFrame(encoded_data, columns=encoded_cols, index = X_test.index)\n",
    "                X_test_ = pd.concat([X_test_[rz_cols], encoded_df], axis = 1)\n",
    "\n",
    "            # Winsorize training and test data\n",
    "            # Ensure no NaN values in the training and test data if not using XGBoost\n",
    "            if model_type != 'xgb':\n",
    "                p001 = X_train.quantile(0.001)\n",
    "                p999 = X_train.quantile(0.999)\n",
    "                X_train = X_train.clip(lower=p001, upper=p999, axis=1)\n",
    "                # Winsorize test data using train percentiles\n",
    "                X_test_ = X_test_.clip(lower=p001, upper=p999, axis=1)\n",
    "\n",
    "                X_train = X_train.fillna(0)\n",
    "                X_test_ = X_test_.fillna(0)\n",
    "            \n",
    "            # Define the model\n",
    "            if model_type == 'lr':\n",
    "                model_path = f'/Users/louisspencer/Desktop/Trading-Bot/data/pretrained_models/classification/lr_model_{next_year}_{next_month}.pkl'\n",
    "            elif model_type == 'nn':\n",
    "                model_path = f'/Users/louisspencer/Desktop/Trading-Bot/data/pretrained_models/classification/nn_model_{next_year}_{next_month}.pkl'\n",
    "            elif model_type == 'xgb':\n",
    "                if direction == 'long':\n",
    "                    model_path = f'/Users/louisspencer/Desktop/Trading-Bot/data/pretrained_models/classification/xgb_long_model_{next_year}_{next_month}.pkl'\n",
    "                else:\n",
    "                    model_path = f'/Users/louisspencer/Desktop/Trading-Bot/data/pretrained_models/classification/xgb_short_model_{next_year}_{next_month}.pkl'\n",
    "\n",
    "            model = joblib.load(model_path)\n",
    "            y_pred_proba = model.predict_proba(X_test_)[:, 1]\n",
    "            y_pred = (y_pred_proba >= 0.7).astype(int)\n",
    "\n",
    "            X_test['y_true'] = y_test\n",
    "            X_test['y_pred'] = y_pred\n",
    "            X_test['y_pred_proba'] = y_pred_proba\n",
    "\n",
    "            # Create cross-sectional predictions\n",
    "            pivot_preds = X_test.pivot_table(index = 'time_period_end', columns = 'symbol_id', values = 'y_pred', dropna = False).fillna(0)\n",
    "            if direction == 'long':\n",
    "                open = X_test.pivot_table(index = 'time_period_end', columns = 'symbol_id', values = 'open_spot', dropna = False)\n",
    "                high = X_test.pivot_table(index = 'time_period_end', columns = 'symbol_id', values = 'high_spot', dropna = False)\n",
    "                low = X_test.pivot_table(index = 'time_period_end', columns = 'symbol_id', values = 'low_spot', dropna = False)\n",
    "                close = X_test.pivot_table(index = 'time_period_end', columns = 'symbol_id', values = 'close_spot', dropna = False)\n",
    "                long_entries = (pivot_preds == 1).astype(bool)\n",
    "                short_entries = np.full(pivot_preds.shape, False, dtype=bool)\n",
    "\n",
    "                market_expectancy = X_test['forward_returns_7'].mean()\n",
    "                market_std_neg = X_test['forward_returns_7'][X_test['forward_returns_7'] < 0].std()\n",
    "                market_sortino_like = market_expectancy / market_std_neg if market_std_neg != 0 else 0\n",
    "                market_hit_rate = (X_test['forward_returns_7'] > 0).mean()\n",
    "\n",
    "                trade_mask = (y_pred == 1)\n",
    "                trade_pnl = X_test['forward_returns_7'] * trade_mask\n",
    "                expectancy = trade_pnl[trade_mask].mean()\n",
    "                std_neg = trade_pnl[trade_mask & (trade_pnl < 0)].std()\n",
    "                sortino_like = expectancy / std_neg if std_neg != 0 else 0\n",
    "                hit_rate = (trade_pnl[trade_mask] > 0).mean()\n",
    "                \n",
    "            else:\n",
    "                open = X_test.pivot_table(index = 'time_period_end', columns = 'symbol_id', values = 'open_futures', dropna = False)\n",
    "                high = X_test.pivot_table(index = 'time_period_end', columns = 'symbol_id', values = 'high_futures', dropna=False)\n",
    "                low = X_test.pivot_table(index = 'time_period_end',columns = 'symbol_id',values = 'low_futures',dropna=False)\n",
    "                close = X_test.pivot_table(index = 'time_period_end',columns = 'symbol_id',values = 'close_futures',dropna=False)\n",
    "                short_entries = (pivot_preds == 1).astype(bool)\n",
    "                long_entries = np.full(pivot_preds.shape, False, dtype=bool)\n",
    "\n",
    "                market_expectancy = -X_test['futures_forward_returns_7'].mean()\n",
    "                market_std_neg = X_test['futures_forward_returns_7'][X_test['futures_forward_returns_7'] > 0].std()\n",
    "                market_sortino_like = market_expectancy / market_std_neg if market_std_neg != 0 else 0\n",
    "                market_hit_rate = (X_test['futures_forward_returns_7'] < 0).mean()\n",
    "\n",
    "                trade_mask = (y_pred == 1)\n",
    "                trade_pnl = -X_test['futures_forward_returns_7'] * trade_mask\n",
    "                expectancy = trade_pnl[trade_mask].mean()\n",
    "                std_neg = trade_pnl[trade_mask & (trade_pnl < 0)].std()\n",
    "                sortino_like = expectancy / std_neg if std_neg != 0 else 0\n",
    "                hit_rate = (trade_pnl[trade_mask] > 0).mean()\n",
    "\n",
    "            # Print market performance\n",
    "            print(f'Expectancy: {expectancy:.3f}, Market Expectancy: {market_expectancy:.3f}')\n",
    "            print(f'Std Negative Returns: {std_neg:.3f}, Market Std Negative Returns: {market_std_neg:.3f}')\n",
    "            print(f'Sortino-Like: {sortino_like:.3f}, Market Sortino-Like: {market_sortino_like:.3f}')\n",
    "            print(f'Hit Rate: {hit_rate:.3f}, Market Hit Rate: {market_hit_rate:.3f}')\n",
    "            print()\n",
    "\n",
    "            # Simulate portfolio\n",
    "            pf = vbt.Portfolio.from_signals(\n",
    "                size_type = 'valuepercent',\n",
    "                init_cash = init_cash,\n",
    "                short_entries = short_entries,\n",
    "                open = open,\n",
    "                high = high,\n",
    "                low = low,\n",
    "                close = close,\n",
    "                sl_stop = 0.2,\n",
    "                size = 0.05,\n",
    "                td_stop = pd.Timedelta(days=7),\n",
    "                cash_sharing = True,\n",
    "                accumulate = False,\n",
    "                freq = 'D'\n",
    "            )\n",
    "            pf_stats = pf.stats()\n",
    "            sharpe = pf_stats['Sharpe Ratio']\n",
    "            sortino = pf_stats['Sortino Ratio']\n",
    "            equity_curve = pf.value.to_frame()\n",
    "            equity_curve = equity_curve.rename({equity_curve.columns[0]:'equity'}, axis = 1)\n",
    "            final_equity = equity_curve['equity'].iloc[-1]\n",
    "            backtest_return = (final_equity - init_cash) / init_cash\n",
    "                        \n",
    "            # Positions\n",
    "            rename_dict = {\n",
    "                'Entry Index':'entry_date', 'Exit Index':'exit_date', \n",
    "                'Column':'symbol_id', 'Size':'size', 'Entry Fees':'entry_fees',\n",
    "                'Exit Fees':'exit_fees', 'PnL':'pnl', 'Return':'pnl_pct', 'Direction':'is_long',\n",
    "                'Status':'status'\n",
    "            }\n",
    "            cols = ['Entry Index', 'Exit Index', 'Column', 'Size', 'Entry Fees', 'Exit Fees', 'PnL', 'Return', 'Direction', 'Status']\n",
    "            positions = pf.positions.records_readable\n",
    "            positions = positions[cols]\n",
    "            positions = positions.rename(rename_dict, axis = 1)\n",
    "            positions.sort_values(by='entry_date', inplace=True)\n",
    "\n",
    "            print('Class Distribution:')\n",
    "            print(X_test['y_true'].value_counts(normalize = True))\n",
    "            print()\n",
    "\n",
    "            trade_side = np.where(\n",
    "                y_pred == 1, 1, 0\n",
    "            )\n",
    "            # Model Performance\n",
    "            hit_rate = (positions['pnl_pct'] > 0).mean()\n",
    "\n",
    "            performance_metrics.append({\n",
    "                'year': next_year,\n",
    "                'month': next_month,\n",
    "                'sortino_annualized': sortino,\n",
    "                'sharpe_annualized': sharpe,\n",
    "                'hit_rate': hit_rate,\n",
    "                'backtest_return': backtest_return,\n",
    "            })\n",
    "            print(f'Initial Equity: {init_cash}, Final Equity: {final_equity:.2f}')\n",
    "            print(f'Backtest Return: {backtest_return:.2%}')\n",
    "            print(f'Sharpe: {sharpe:.3f}, Sortino: {sortino:.3f}, Hit Rate: {hit_rate:.3f}')\n",
    "            print()\n",
    "\n",
    "            init_cash = final_equity  # Update initial cash for the next month\n",
    "\n",
    "            # Classification Report\n",
    "            print('Classification Report:')\n",
    "            print(classification_report(X_test['y_true'], X_test['y_pred']))\n",
    "            print()\n",
    "\n",
    "            # Calibration Curve\n",
    "            disp = CalibrationDisplay.from_predictions(y_test, y_pred_proba)\n",
    "            plt.show()\n",
    "\n",
    "            precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "            pr_auc = auc(recall, precision)\n",
    "\n",
    "            if model_type == 'lr':\n",
    "                # Subplots 2 columns, 1 row\n",
    "                fig, ax = plt.subplots(1, 2, figsize=(15, 7))\n",
    "\n",
    "                # Top 50 most important positive features\n",
    "                top_n_pos = 50\n",
    "                feature_importances = pd.Series(model.coef_[0], index=X_test_.columns)\n",
    "                feature_importances = feature_importances.sort_values().tail(top_n_pos)\n",
    "                feature_importances.plot(kind='barh', title='Top 50 Most Important Features', ax=ax[0])\n",
    "\n",
    "                # Top 50 most important negative features\n",
    "                top_n_neg = 50\n",
    "                feature_importances_neg = pd.Series(model.coef_[0], index=X_test_.columns)\n",
    "                feature_importances_neg = feature_importances_neg.sort_values().head(top_n_neg)\n",
    "                feature_importances_neg.plot(kind='barh', title='Top 50 Most Important Negative Features', ax=ax[1])\n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "            elif model_type == 'xgb':\n",
    "                try:\n",
    "                    fig, ax = plt.subplots(figsize=(15, 7))\n",
    "                    # Plot feature importance\n",
    "                    xgb.plot_importance(model, max_num_features=50, importance_type='gain', ax=ax, title='Top 50 Most Important Features')\n",
    "                    plt.show()\n",
    "                except Exception as e:\n",
    "                    print(f'Error plotting feature importance: {e}')\n",
    "                    print()\n",
    "\n",
    "            # Delete old data from memory\n",
    "            del X_train\n",
    "            del X_test\n",
    "            del data_train\n",
    "            del data_test\n",
    "\n",
    "    # Convert performance metrics to DataFrame\n",
    "    performance_df = pd.DataFrame(performance_metrics)\n",
    "    performance_df.to_csv(f'/Users/louisspencer/Desktop/Trading-Bot/data/performance_metrics_{model_type}_{direction}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_performance_metrics(2020, 2025, is_reg=False, model_type='xgb', direction='short')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf = pd.read_csv('/Users/louisspencer/Desktop/Trading-Bot/notebooks/performance_metrics_xgb.csv')\n",
    "perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_month_pos = (perf['backtest_return'] > 0).mean()\n",
    "expectancy_pos_months = perf[perf['backtest_return'] > 0]\n",
    "expectancy_neg_months = perf[perf['backtest_return'] <= 0]\n",
    "expectancy_months_annualized = perf['backtest_return'].mean() \n",
    "\n",
    "print(f'Average Monthly Return: {expectancy_months:.3f}')\n",
    "print(f'Average Return of positive months: {expectancy_pos_months[\"backtest_return\"].mean():.3f}')\n",
    "print(f'Average Return of negative months: {expectancy_neg_months[\"backtest_return\"].mean():.3f}')\n",
    "print(f'Average Monthly Sharpe Ratio (Annualized): {perf[\"sharpe_annualized\"].mean():.3f}')\n",
    "print(f'Average Monthly Sortino Ratio (Annualized): {perf[\"sortino_annualized\"].mean():.3f}')\n",
    "print(f'Average Monthly Hit Rate: {perf[\"hit_rate\"].mean():.3f}')\n",
    "print(f'Percentage of months with positive returns: {pct_month_pos:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf['date'] = pd.to_datetime(perf['year'].astype(str) + '-' + perf['month'].astype(str) + '-01')\n",
    "perf['month'] = perf['date'].dt.strftime('%Y-%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Plot monthly backtest returns with Plotly\n",
    "backtest_res = (perf.set_index('date')['backtest_return'] + 1).cumprod()\n",
    "fig = px.line(\n",
    "    backtest_res, \n",
    "    title='Cumulative Backtest Returns Over Time',\n",
    "    labels={'value': 'Cumulative Return', 'date': 'Date'},\n",
    "    markers=True\n",
    ")\n",
    "fig.update_layout(\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Cumulative Return',\n",
    "    xaxis_rangeslider_visible=True,\n",
    "    template='plotly_dark'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf.head(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
