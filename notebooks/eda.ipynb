{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Models and metrics\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "\n",
    "# Classification metrics\n",
    "from sklearn.metrics import classification_report, precision_recall_curve, auc, r2_score\n",
    "from sklearn.calibration import calibration_curve, CalibrationDisplay, CalibratedClassifierCV\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Suppress all warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Other imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "from utils.db_utils import QUERY\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T06:44:59.784015Z",
     "start_time": "2025-05-24T06:44:58.417442Z"
    }
   },
   "cell_type": "code",
   "source": "ml_features = pd.read_parquet('/Users/louisspencer/Desktop/Trading-Bot/data/ml_features.parquet').columns",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T06:44:59.800638Z",
     "start_time": "2025-05-24T06:44:59.787892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(min_year, max_year, is_reg):\n",
    "    for year in range(min_year, max_year + 1):\n",
    "        # Train XGBoost model for each month\n",
    "        for month in range(1, 13):\n",
    "            # if year < 2023 or (year == 2023 and month < 4):\n",
    "            #     continue\n",
    "\n",
    "            data_train = QUERY(\n",
    "                f\"\"\"\n",
    "                SELECT *\n",
    "                FROM market_data.ml_features\n",
    "                WHERE\n",
    "                    date_part('year', time_period_end) < {year} OR\n",
    "                    (date_part('year', time_period_end) = {year} AND\n",
    "                     date_part('month', time_period_end) <= {month})\n",
    "                \"\"\"\n",
    "            )\n",
    "            data_train['symbol_id'] = (\n",
    "                data_train['asset_id_base'].str.upper() +\n",
    "                '_' +\n",
    "                data_train['asset_id_quote'].str.upper() +\n",
    "                '_' +\n",
    "                data_train['exchange_id'].str.upper()\n",
    "            ).astype('category')\n",
    "\n",
    "            max_train_date = pd.to_datetime(data_train['time_period_end'].dt.date.max())\n",
    "            min_train_date = pd.to_datetime(max_train_date - pd.Timedelta(days = 365 * 2))\n",
    "\n",
    "            # Test data is all data in the next month\n",
    "            next_month = month + 1\n",
    "            if next_month == 13:\n",
    "                next_year = year + 1\n",
    "                next_month = 1\n",
    "            else:\n",
    "                next_year = year\n",
    "\n",
    "            data_test = QUERY(\n",
    "                f\"\"\"\n",
    "                SELECT *\n",
    "                FROM market_data.ml_features\n",
    "                WHERE\n",
    "                    time_period_end > '{max_train_date}' AND\n",
    "                    date_part('year', time_period_end) = {next_year} AND\n",
    "                    date_part('month', time_period_end) <= {next_month}\n",
    "                \"\"\"\n",
    "            )\n",
    "            data_test['symbol_id'] = (\n",
    "                data_test['asset_id_base'].str.upper() +\n",
    "                '_' +\n",
    "                data_test['asset_id_quote'].str.upper() +\n",
    "                '_' +\n",
    "                data_test['exchange_id'].str.upper()\n",
    "            ).astype('category')\n",
    "\n",
    "            data_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "            data_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "            # Filter out data with nan trade_returns_h7\n",
    "            data_train = data_train.dropna(subset = ['forward_returns_7'])\n",
    "            data_test = data_test.dropna(subset = ['forward_returns_7'])\n",
    "\n",
    "            # Filter out training data older than 2 years from the max train date\n",
    "            filter_train = (\n",
    "                data_train['time_period_end'] >= min_train_date\n",
    "            )\n",
    "            filter_test = (\n",
    "            )\n",
    "            data_train = data_train[filter_train]\n",
    "            # data_test = data_test[filter_test]\n",
    "\n",
    "            data_train['symbol_id'] = data_train['symbol_id'].astype('category')\n",
    "            data_test['symbol_id'] = data_test['symbol_id'].astype('category')\n",
    "\n",
    "            if data_train.empty or data_test.empty:\n",
    "                continue\n",
    "\n",
    "            X_train = data_train\n",
    "            X_test = data_test\n",
    "\n",
    "            # Split data into features and target\n",
    "            if is_reg:\n",
    "                y_train = X_train['forward_returns_7'].clip(-1,1).abs()\n",
    "                y_test = X_test['forward_returns_7'].clip(-1,1).abs()\n",
    "            else:\n",
    "                y_train = (X_train['forward_returns_7'] > 0).astype(int)\n",
    "                y_test = (X_test['forward_returns_7'] > 0).astype(int)\n",
    "\n",
    "            print()\n",
    "            print(f'Train Date Range: {X_train[\"time_period_end\"].min()} - {X_train[\"time_period_end\"].max()}')\n",
    "            print(f'Number of observations (Train): {X_train.shape[0]}')\n",
    "            print()\n",
    "\n",
    "            print(f'Test Date Range: {X_test[\"time_period_end\"].min()} - {X_test[\"time_period_end\"].max()}')\n",
    "            print(f'Number of observations (Test): {X_test.shape[0]}')\n",
    "            print()\n",
    "\n",
    "            # Ensure no data leakage\n",
    "            data_leakage_indicator = (\n",
    "                (X_train['time_period_end'].max() >= X_test['time_period_end'].min())\n",
    "            )\n",
    "            assert not data_leakage_indicator, 'Data leakage detected'\n",
    "\n",
    "            # Define the model\n",
    "            if is_reg:\n",
    "                ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "                X_train = X_train.drop(columns = cols_to_drop, axis = 1, errors = 'ignore')\n",
    "\n",
    "                encoded_data = ohe.fit_transform(X_train[['symbol_id']])\n",
    "                encoded_cols = ohe.get_feature_names_out(['symbol_id'])\n",
    "                encoded_df = pd.DataFrame(encoded_data, columns = encoded_cols, index = X_train.index)\n",
    "\n",
    "                X_train = pd.concat([X_train, encoded_df], axis = 1).drop('symbol_id', axis = 1).fillna(0)\n",
    "\n",
    "                model = MLPRegressor(hidden_layer_sizes=(100,), verbose=True)\n",
    "                model.fit(\n",
    "                    X_train,\n",
    "                    y_train\n",
    "                )\n",
    "            else:\n",
    "                ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "                X_train = X_train.drop(columns = cols_to_drop, axis = 1, errors = 'ignore')\n",
    "                encoded_data = ohe.fit_transform(X_train[['symbol_id']])\n",
    "                encoded_cols = ohe.get_feature_names_out()\n",
    "                encoded_df = pd.DataFrame(encoded_data, columns = encoded_cols, index = X_train.index)\n",
    "                X_train = pd.concat([X_train, encoded_df], axis = 1).drop('symbol_id', axis = 1).fillna(0)\n",
    "\n",
    "                model = LogisticRegression(n_jobs=-1, max_iter = 2000)\n",
    "                # model = MLPClassifier(hidden_layer_sizes=(100,100), alpha = 1, max_iter = 50)\n",
    "                model.fit(\n",
    "                    X_train,\n",
    "                    y_train\n",
    "                )\n",
    "\n",
    "            if is_reg:\n",
    "                # Constant model (mean)\n",
    "                y_pred_const = [y_train.mean()] * len(y_test)\n",
    "                mae_const = mean_absolute_error(y_test, y_pred_const)\n",
    "\n",
    "                # Constant model (zero)\n",
    "                y_pred_zero = np.zeros(len(y_test))\n",
    "                mae_zero = mean_absolute_error(y_test, y_pred_zero)\n",
    "\n",
    "                encoded_data = ohe.transform(X_test[['symbol_id']])\n",
    "                encoded_cols = ohe.get_feature_names_out(['symbol_id'])\n",
    "                encoded_df = pd.DataFrame(encoded_data, columns=encoded_cols, index = X_test.index)\n",
    "\n",
    "                X_test_ = X_test.drop(columns = cols_to_drop, axis = 1, errors = 'ignore')\n",
    "                X_test_ = pd.concat([X_test_, encoded_df], axis = 1).drop('symbol_id', axis = 1).fillna(0)\n",
    "\n",
    "                # Linear regression model\n",
    "                y_pred = model.predict(X_test_)\n",
    "                mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "                # R2\n",
    "                r2_model = r2_score(y_test, y_pred)\n",
    "\n",
    "                print(f'MAE (Lin. Reg.): {mae}')\n",
    "                print(f'MAE (Naive mean): {mae_const}')\n",
    "                print(f'MAE (Naive zero): {mae_zero}')\n",
    "                print(f'R^2 (Lin. Reg): {r2_model}')\n",
    "                print()\n",
    "\n",
    "                # Subplots 2 columns, 1 row\n",
    "                fig, ax = plt.subplots(1, 2, figsize=(15, 7))\n",
    "                # Predicted vs. Actual Plot\n",
    "                ax[0].scatter(y_test, y_pred, alpha=0.5)\n",
    "                ax[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "                ax[0].set_xlabel('True Values')\n",
    "                ax[0].set_ylabel('Predicted Values')\n",
    "                ax[0].set_title('Predicted vs Actual')\n",
    "\n",
    "                # Plot feature importances\n",
    "                # top_n = 50\n",
    "                # feature_importances = pd.Series(model.coef_, index=X_test_.columns)\n",
    "                # feature_importances = feature_importances.sort_values().tail(top_n)\n",
    "                # feature_importances.plot(kind='barh', ax = ax[1])\n",
    "                # ax[1].set_title(f'Top {top_n} Most Important Features')\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "            else:\n",
    "                encoded_data = ohe.transform(X_test[['symbol_id']])\n",
    "                encoded_cols = ohe.get_feature_names_out(['symbol_id'])\n",
    "                encoded_df = pd.DataFrame(encoded_data, columns=encoded_cols, index = X_test.index)\n",
    "\n",
    "                X_test_ = X_test.drop(columns = cols_to_drop, axis = 1, errors = 'ignore')\n",
    "                X_test_ = pd.concat([X_test_, encoded_df], axis = 1).drop('symbol_id', axis = 1).fillna(0)\n",
    "\n",
    "                y_pred_proba = model.predict_proba(X_test_)[:, 1]\n",
    "                y_pred = (y_pred_proba >= 0.7).astype(int)\n",
    "\n",
    "                X_test['y_true'] = y_test\n",
    "                X_test['y_pred'] = y_pred\n",
    "                X_test['y_pred_proba'] = y_pred_proba\n",
    "\n",
    "                print('Class Distribution:')\n",
    "                print(X_test['y_true'].value_counts(normalize = True))\n",
    "                print()\n",
    "\n",
    "                trade_side = np.where(\n",
    "                    y_pred == 1, 1, 0\n",
    "                )\n",
    "                trade_pnl = trade_side * X_test['forward_returns_7'].values\n",
    "                expectancy = trade_pnl[trade_side == 1].mean()\n",
    "                hit_rate = (trade_pnl[trade_side == 1] > 0).mean()\n",
    "                payoff_ratio = trade_pnl[trade_pnl>0].mean() / abs(trade_pnl[trade_pnl<0].mean())\n",
    "\n",
    "                print(f'Expectancy: {expectancy}')\n",
    "                print(f'Hit Rate: {hit_rate}')\n",
    "                print(f'Payoff Ratio: {payoff_ratio}')\n",
    "                print()\n",
    "\n",
    "                # Classification Report\n",
    "                print('Classification Report:')\n",
    "                print(classification_report(X_test['y_true'], X_test['y_pred']))\n",
    "                print()\n",
    "\n",
    "                # Calibration Curve\n",
    "                disp = CalibrationDisplay.from_predictions(y_test, y_pred_proba)\n",
    "                plt.show()\n",
    "\n",
    "                precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "                pr_auc = auc(recall, precision)\n",
    "\n",
    "                # Subplots 2 columns, 1 row\n",
    "                fig, ax = plt.subplots(1, 2, figsize=(15, 7))\n",
    "\n",
    "                # Plot Precision Recall Curve with area under curve filled\n",
    "                ax[0].plot(recall, precision, marker='.')\n",
    "                ax[0].set_title(f'Precision Recall Curve: AUC={pr_auc:.2f}')\n",
    "                ax[0].set_xlabel('Recall')\n",
    "                ax[0].set_ylabel('Precision')\n",
    "\n",
    "                # Plot feature importances\n",
    "                top_n = 50\n",
    "                feature_importances = pd.Series(model.coef_[0], index=X_test_.columns)\n",
    "                feature_importances = feature_importances.sort_values().tail(top_n)\n",
    "                feature_importances.plot(kind='barh', ax = ax[1])\n",
    "                ax[1].set_title(f'Top {top_n} Most Important Features')\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "            # Delete old data from memory\n",
    "            del X_train\n",
    "            del X_test\n",
    "            del data_train\n",
    "            del data_test\n",
    "\n",
    "            # Save the calibrated model and performance metrics\n",
    "            if is_reg:\n",
    "                path = f'/Users/louisspencer/Desktop/Trading-Bot/data/pretrained_models/regression/lr_model_{year}_{month}.pkl'\n",
    "            else:\n",
    "                path = f'/Users/louisspencer/Desktop/Trading-Bot/data/pretrained_models/classification/lr_model_{year}_{month}.pkl'\n",
    "\n",
    "            # Save model and its best prediction threshold on validation data\n",
    "            joblib.dump(model, path)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T06:44:59.810048Z",
     "start_time": "2025-05-24T06:44:59.806714Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Columns we need to drop before training the model\n",
    "triple_barrier_label_cols = [\n",
    "    col for col in ml_features if 'triple_barrier_label_h' in col\n",
    "]\n",
    "\n",
    "trade_returns_cols = [\n",
    "    col for col in ml_features if 'trade_returns' in col\n",
    "]\n",
    "\n",
    "forward_returns_cols = [col for col in ml_features if 'forward_returns' in col]\n",
    "\n",
    "non_numeric_cols = [\n",
    "    'Unnamed: 0', 'sample_weight', 'y_true', 'y_pred', 'y_pred_proba', 'asset_id_base', 'asset_id_quote', 'exchange_id'\n",
    "]\n",
    "\n",
    "other_cols = [\n",
    "    'open', 'high', 'low', 'close', 'volume', 'trades', 'start_date_triple_barrier_label_h7', 'start_date_triple_barrier_label_h1', 'end_date_triple_barrier_label_h1',\n",
    "    'end_date_triple_barrier_label_h7', 'avg_uniqueness', 'time_period_end',\n",
    "    'total_buy_dollar_volume_1d', 'total_buy_dollar_volume_7d', 'total_buy_dollar_volume_30d', 'total_buy_dollar_volume_90d',\n",
    "    'total_buy_dollar_volume_180d', 'total_buy_dollar_volume_365d',  'total_sell_dollar_volume_1d', 'total_sell_dollar_volume_7d',\n",
    "    'total_sell_dollar_volume_30d', 'total_sell_dollar_volume_90d', 'total_sell_dollar_volume_180d', 'total_sell_dollar_volume_365d',\n",
    "    'num_buys_1d', 'num_buys_7d', 'num_buys_30d', 'num_buys_90d', 'num_buys_180d', 'num_buys_365d',\n",
    "    'num_sells_1d', 'num_sells_7d', 'num_sells_30d', 'num_sells_90d', 'num_sells_180d', 'num_sells_365d',\n",
    "]\n",
    "\n",
    "rz_cols = [col for col in ml_features if '_rz' in col and 'forward_returns' not in col] + ['symbol_id']\n",
    "\n",
    "cols_to_drop = (\n",
    "    triple_barrier_label_cols +\n",
    "    trade_returns_cols +\n",
    "    non_numeric_cols +\n",
    "    forward_returns_cols +\n",
    "    other_cols\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T06:45:00.030187Z",
     "start_time": "2025-05-24T06:44:59.820737Z"
    }
   },
   "cell_type": "code",
   "source": "train_model(2019, 2024, is_reg=False)",
   "outputs": [
    {
     "ename": "IOException",
     "evalue": "IO Error: Could not set lock on file \"/Users/louisspencer/Desktop/Trading-Bot-Data-Pipelines/data/database.db\": Conflicting lock is held in /Library/Frameworks/Python.framework/Versions/3.11/Resources/Python.app/Contents/MacOS/Python (PID 10878) by user louisspencer. See also https://duckdb.org/docs/connect/concurrency",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIOException\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m2019\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2024\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_reg\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[7], line 8\u001B[0m, in \u001B[0;36mtrain_model\u001B[0;34m(min_year, max_year, is_reg)\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m year \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(min_year, max_year \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;66;03m# Train XGBoost model for each month\u001B[39;00m\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m month \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m13\u001B[39m):\n\u001B[1;32m      5\u001B[0m         \u001B[38;5;66;03m# if year < 2023 or (year == 2023 and month < 4):\u001B[39;00m\n\u001B[1;32m      6\u001B[0m         \u001B[38;5;66;03m#     continue\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m         data_train \u001B[38;5;241m=\u001B[39m \u001B[43mQUERY\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\"\"\u001B[39;49m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;124;43m            SELECT *\u001B[39;49m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;124;43m            FROM market_data.ml_features\u001B[39;49m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;124;43m            WHERE\u001B[39;49m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;124;43m                date_part(\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43myear\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m, time_period_end) < \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43myear\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m OR\u001B[39;49m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;124;43m                (date_part(\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43myear\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m, time_period_end) = \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43myear\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m AND\u001B[39;49m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;124;43m                 date_part(\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmonth\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m, time_period_end) <= \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mmonth\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m)\u001B[39;49m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;124;43m            \u001B[39;49m\u001B[38;5;124;43m\"\"\"\u001B[39;49m\n\u001B[1;32m     17\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m         data_train[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msymbol_id\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m     19\u001B[0m             data_train[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124masset_id_base\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mstr\u001B[38;5;241m.\u001B[39mupper() \u001B[38;5;241m+\u001B[39m\n\u001B[1;32m     20\u001B[0m             \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     23\u001B[0m             data_train[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mexchange_id\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mstr\u001B[38;5;241m.\u001B[39mupper()\n\u001B[1;32m     24\u001B[0m         )\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcategory\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     26\u001B[0m         max_train_date \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mto_datetime(data_train[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtime_period_end\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mdt\u001B[38;5;241m.\u001B[39mdate\u001B[38;5;241m.\u001B[39mmax())\n",
      "File \u001B[0;32m~/Desktop/Trading-Bot/utils/db_utils.py:14\u001B[0m, in \u001B[0;36mQUERY\u001B[0;34m(query, conn)\u001B[0m\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;66;03m# Connect to DuckDB\u001B[39;00m\n\u001B[0;32m---> 14\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mduckdb\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdatabase\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m/Users/louisspencer/Desktop/Trading-Bot-Data-Pipelines/data/database.db\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m        \u001B[49m\u001B[43mread_only\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[1;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m conn:\n\u001B[1;32m     18\u001B[0m         \u001B[38;5;66;03m# Execute the query\u001B[39;00m\n\u001B[1;32m     19\u001B[0m         result \u001B[38;5;241m=\u001B[39m conn\u001B[38;5;241m.\u001B[39msql(query)\n\u001B[1;32m     20\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mIOException\u001B[0m: IO Error: Could not set lock on file \"/Users/louisspencer/Desktop/Trading-Bot-Data-Pipelines/data/database.db\": Conflicting lock is held in /Library/Frameworks/Python.framework/Versions/3.11/Resources/Python.app/Contents/MacOS/Python (PID 10878) by user louisspencer. See also https://duckdb.org/docs/connect/concurrency"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
