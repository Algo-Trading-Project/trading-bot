{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering and model selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report, precision_recall_curve, auc, roc_curve\n",
    "\n",
    "# Classification models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Suppress all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import vectorbt as vbt\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "# Custom imports to prevent clutter\n",
    "from helper import *\n",
    "from custom_transformers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Load the data\n",
    "df = construct_dataset_for_ml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('dataset shape:', df.shape)\n",
    "print(f'database size: {df.memory_usage(deep = True).sum() / 1e9} GB')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [col for col in df.columns if col not in ('symbol_id')]\n",
    "categorical_cols = ['symbol_id']\n",
    "\n",
    "df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, downcast = 'float')\n",
    "df['triple_barrier_label'] = pd.to_numeric(df['triple_barrier_label'], downcast = 'integer')\n",
    "df[categorical_cols] = df[categorical_cols].astype('category')\n",
    "\n",
    "print(f'database size: {df.memory_usage(deep = True).sum() / 1e9} GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_columns(X):\n",
    "    # Remove one_hot__ and remainder__ from column names\n",
    "    X.columns = X.columns.str.replace('one_hot__', '')\n",
    "    X.columns = X.columns.str.replace('remainder__', '')\n",
    "    X.columns = X.columns.str.replace('symbol_id_', '')\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify window sizes for rolling min-max and z-score scaling\n",
    "window_sizes_scaling = [2 * 24, 2 * 24 * 7, 2 * 24 * 30]\n",
    "\n",
    "# Specify window sizes for returns-based features\n",
    "window_sizes_returns = [1, 2 * 24, 2 * 24 * 7, 2 * 24 * 30]\n",
    "\n",
    "# Pipeline for feature engineering and modeling\n",
    "feature_engineering_pipeline = Pipeline([\n",
    "\n",
    "    # Add returns-based features to the dataset\n",
    "    ('returns_features', ReturnsFeatures(window_sizes_returns)),\n",
    "\n",
    "    # Add rolling min-max scaled features to the dataset\n",
    "    ('rolling_min_max_scaler', RollingMinMaxScaler(window_sizes_scaling)),\n",
    "\n",
    "    # Add rolling z-score scaled features to the dataset\n",
    "    ('rolling_z_score_scaler', RollingZScoreScaler(window_sizes_scaling)),\n",
    "\n",
    "    # Add price-based features to the dataset\n",
    "    # ('price_features', PriceFeatures()),\n",
    "\n",
    "    # Add more feature engineering steps here\n",
    "    # ...\n",
    "    # ...\n",
    "\n",
    "    # Clean NaN/infinity values from the dataset\n",
    "    ('fill_nan', FillNaN()),\n",
    "\n",
    "    # Add lagged features to the dataset\n",
    "    ('lag_features', LagFeatures(lags = [1, 2, 3])),\n",
    "\n",
    "    # Add time-based features to the dataset\n",
    "    # ('time_features', TimeFeatures()),\n",
    "\n",
    "])\n",
    "\n",
    "data_cleaning_pipeline = Pipeline([\n",
    "    \n",
    "    # One-hot encode the symbol_id column\n",
    "    ('one_hot_encoding', ColumnTransformer(\n",
    "        transformers = [\n",
    "            ('one_hot', OneHotEncoder(sparse_output=False), ['symbol_id'])\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "        )\n",
    "    ),\n",
    "\n",
    "    # Clean the column names\n",
    "    ('clean_column_names', FunctionTransformer(clean_columns))\n",
    "    \n",
    "]).set_output(transform = 'pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "X_train, X_test, y_train, y_test = [], [], [], []\n",
    "i = 1\n",
    "n = len(df.symbol_id.unique())\n",
    "\n",
    "for symbol_id in df.symbol_id.unique():\n",
    "    print(f'Processing symbol_id: {symbol_id} ({i}/{n})')\n",
    "    i += 1\n",
    "\n",
    "    token = df[df.symbol_id == symbol_id]\n",
    "    \n",
    "    labels = token['triple_barrier_label']\n",
    "    features = feature_engineering_pipeline.fit_transform(token.drop(['triple_barrier_label'], axis = 1))\n",
    "\n",
    "    train_pct = 0.8\n",
    "    train_size = int(train_pct * len(features))\n",
    "\n",
    "    X_train.append(features[:train_size])\n",
    "    X_test.append(features[train_size:])\n",
    "    y_train.append(labels[:train_size])\n",
    "    y_test.append(labels[train_size:])\n",
    "\n",
    "X_train = pd.concat(X_train)\n",
    "X_test = pd.concat(X_test)\n",
    "y_train = pd.concat(y_train)\n",
    "y_test = pd.concat(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'X_train size: {X_train.memory_usage(deep = True).sum() / 1e9} GB')\n",
    "print(f'X_test size: {X_test.memory_usage(deep = True).sum() / 1e9} GB')\n",
    "print()\n",
    "print('X_train shape: ', X_train.shape)\n",
    "print('X_test shape: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [col for col in X_train.columns if col not in ('symbol_id')]\n",
    "categorical_cols = ['symbol_id']\n",
    "\n",
    "# Downcast data to save memory\n",
    "X_train[numeric_cols] = X_train[numeric_cols].apply(pd.to_numeric, downcast = 'float')\n",
    "X_train[categorical_cols] = X_train[categorical_cols].astype('category')\n",
    "\n",
    "X_test[numeric_cols] = X_test[numeric_cols].apply(pd.to_numeric, downcast = 'float')\n",
    "X_test[categorical_cols] = X_test[categorical_cols].astype('category')\n",
    "\n",
    "print(f'X_train size: {X_train.memory_usage(deep = True).sum() / 1e9} GB')\n",
    "print(f'X_test size: {X_test.memory_usage(deep = True).sum() / 1e9} GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# One-hot encode the symbol_id column\n",
    "X_train = data_cleaning_pipeline.fit_transform(X_train)\n",
    "X_test = data_cleaning_pipeline.fit_transform(X_test)\n",
    "\n",
    "print(f'X_train size: {X_train.memory_usage(deep = True).sum() / 1e9} GB')\n",
    "print(f'X_test size: {X_test.memory_usage(deep = True).sum() / 1e9} GB')\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = max(X_train.index)\n",
    "df[df.index <= end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Y train distribution:')\n",
    "print(y_train.value_counts(normalize = True))\n",
    "print()\n",
    "print('Y test distribution:')\n",
    "print(y_test.value_counts(normalize = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['symbol_id'], axis = 1)\n",
    "X_test = X_test.drop(['symbol_id'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    bootstrap = False, \n",
    "    random_state = 9 + 10, \n",
    "    n_jobs = -1,\n",
    "    verbose = True\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Predictions on the training and test set\n",
    "y_pred_train_rf = rf.predict(X_train)\n",
    "y_pred_test_rf = rf.predict(X_test)\n",
    "\n",
    "# Predicted probabilities on the test set\n",
    "y_pred_proba_test_rf = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Classification reports for the training and test set\n",
    "print('RF Train:')\n",
    "print(classification_report(y_train, y_pred_train_rf))\n",
    "print()\n",
    "print('RF Test:')\n",
    "print(classification_report(y_test, y_pred_test_rf))\n",
    "\n",
    "# Precision-recall curve and AUC\n",
    "precision_rf, recall_rf, _ = precision_recall_curve(y_test, y_pred_proba_test_rf)\n",
    "auc_rf = auc(recall_rf, precision_rf)\n",
    "\n",
    "# ROC curve and AUC\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_proba_test_rf)\n",
    "roc_auc_rf = auc(fpr_rf, tpr_rf)\n",
    "\n",
    "print(f'Random Forest ROC AUC: {roc_auc_rf}')\n",
    "print(f'Random Forest Precision-Recall AUC: {auc_rf}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot precision-recall curve and ROC curve side by side\n",
    "plt.figure(figsize = (14, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(recall_rf, precision_rf, label = 'RF', linestyle = 'dashed', color = 'b')\n",
    "plt.fill_between(recall_rf, precision_rf, alpha = 0.2, color = 'b')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title(f'Precision-Recall Curve (AUC = {auc_rf:.2f})')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(fpr_rf, tpr_rf, label = 'RF', marker = '.')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label='No Skill')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(f'ROC Curve (AUC = {roc_auc_rf:.2f})')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top N most important features as horizontal bar plot\n",
    "top_n = 30\n",
    "feature_importances = pd.Series(rf.feature_importances_, index = X_train.columns)\n",
    "feature_importances = feature_importances.sort_values().tail(top_n)\n",
    "\n",
    "plt.figure(figsize = (10, 6))\n",
    "feature_importances.plot(kind = 'barh')\n",
    "plt.title(f'Top {top_n} Most Important Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_dict = {\n",
    "    'prediction_threshold': [0.6, 2],\n",
    "    'trade_size_multiplier': [0.2,2]\n",
    "}\n",
    "def k(**kwargs):\n",
    "    print(kwargs)\n",
    "\n",
    "k(**optimize_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
