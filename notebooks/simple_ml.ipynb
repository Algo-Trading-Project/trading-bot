{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import redshift_connector\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', pd.errors.PerformanceWarning)\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "from numba import njit\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "from ta.momentum import RSIIndicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_tokens():\n",
    "    with redshift_connector.connect(\n",
    "        host = 'project-poseidon.cpsnf8brapsd.us-west-2.redshift.amazonaws.com',\n",
    "        database = 'token_price',\n",
    "        user = 'administrator',\n",
    "        password = 'Free2play2'\n",
    "    ) as conn:\n",
    "        with conn.cursor() as cursor:\n",
    "            query = \"\"\"\n",
    "            WITH num_days_data AS (\n",
    "                SELECT \n",
    "                    asset_id_base,\n",
    "                    asset_id_quote,\n",
    "                    exchange_id,\n",
    "                    COUNT(*) / 24.0 AS num_days_data\n",
    "                FROM token_price.coinapi.price_data_1h\n",
    "                GROUP BY asset_id_base, asset_id_quote, exchange_id\n",
    "            ), \n",
    "            ordered_pairs_by_data_size AS (\n",
    "                SELECT\n",
    "                    *,\n",
    "                    ROW_NUMBER() OVER (PARTITION BY asset_id_base \n",
    "                                       ORDER BY num_days_data DESC) AS pos\n",
    "                FROM num_days_data\n",
    "            )\n",
    "\n",
    "            SELECT \n",
    "                asset_id_base,\n",
    "                asset_id_quote,\n",
    "                exchange_id\n",
    "            FROM ordered_pairs_by_data_size\n",
    "            WHERE \n",
    "                pos = 1 AND\n",
    "                num_days_data >= 365\n",
    "            ORDER BY asset_id_base, asset_id_quote, exchange_id\n",
    "            \"\"\"\n",
    "\n",
    "            # Execute query on Redshift and return result as DataFrame\n",
    "            cursor.execute(query)\n",
    "            df = cursor.fetch_dataframe()\n",
    "            \n",
    "            return df\n",
    "        \n",
    "def fetch_OHLCV_df_from_redshift(asset_id_base, asset_id_quote, exchange_id):\n",
    "    # Connect to Redshift cluster containing price data\n",
    "    with redshift_connector.connect(\n",
    "        host = 'project-poseidon.cpsnf8brapsd.us-west-2.redshift.amazonaws.com',\n",
    "        database = 'token_price',\n",
    "        user = 'administrator',\n",
    "        password = 'Free2play2'\n",
    "    ) as conn:\n",
    "        with conn.cursor() as cursor:\n",
    "            # Query to fetch OHLCV data for a token & exchange of interest\n",
    "            title = asset_id_base + '-' + asset_id_quote\n",
    "            query = \"\"\"\n",
    "            SELECT \n",
    "                time_period_end,\n",
    "                price_open,\n",
    "                price_high,\n",
    "                price_low,\n",
    "                price_close,\n",
    "                volume_traded\n",
    "            FROM token_price.coinapi.price_data_1h\n",
    "            WHERE \n",
    "                asset_id_base = '{}' AND\n",
    "                asset_id_quote = '{}' AND\n",
    "                exchange_id = '{}'\n",
    "            ORDER BY time_period_start ASC\n",
    "            \"\"\".format(asset_id_base, asset_id_quote, \n",
    "                        exchange_id)\n",
    "\n",
    "            # Execute query on Redshift and return result as a DataFrame\n",
    "            cursor.execute(query)\n",
    "\n",
    "            df = cursor.fetch_dataframe().rename({'time_period_end':'Date'}, axis = 1).set_index('Date').astype(float)\n",
    "            return df\n",
    "        \n",
    "def fetch_blockchain_metrics():\n",
    "    # Connect to Redshift cluster containing price data\n",
    "    with redshift_connector.connect(\n",
    "        host = 'project-poseidon.cpsnf8brapsd.us-west-2.redshift.amazonaws.com',\n",
    "        database = 'administrator',\n",
    "        user = 'administrator',\n",
    "        password = 'Free2play2'\n",
    "    ) as conn:\n",
    "        with conn.cursor() as cursor:\n",
    "            # Query to fetch OHLCV data for a token & exchange of interest\n",
    "            query = \"\"\"\n",
    "            WITH total_eth_sent_per_block AS (\n",
    "                SELECT\n",
    "                    b.block_no,\n",
    "                    timestamp 'epoch' + \"timestamp\" * interval '1 second' AS \"timestamp\",\n",
    "                    SUM(t.value) AS total_transaction_value\n",
    "                FROM eth_data.transaction t INNER JOIN eth_data.block b\n",
    "                    ON t.block_no = b.block_no\n",
    "                GROUP BY\n",
    "                    b.block_no,\n",
    "                    b.timestamp\n",
    "                ORDER BY b.block_no\n",
    "            ),\n",
    "            eth_usd_coinbase AS (\n",
    "                SELECT \n",
    "                    time_period_start,\n",
    "                    time_period_end\n",
    "                FROM token_price.coinapi.price_data_1h\n",
    "                WHERE\n",
    "                    asset_id_base = 'ETH' AND\n",
    "                    asset_id_quote = 'USD' AND\n",
    "                    exchange_id = 'COINBASE'\n",
    "            ),\n",
    "            total_eth_sent_per_hour AS (\n",
    "                SELECT\n",
    "                    e.time_period_end,\n",
    "                    SUM(t.total_transaction_value) AS total_eth_sent_per_hour\n",
    "                FROM total_eth_sent_per_block t INNER JOIN eth_usd_coinbase e\n",
    "                    ON t.timestamp >= e.time_period_start AND\n",
    "                        t.timestamp < e.time_period_end \n",
    "                GROUP BY e.time_period_end\n",
    "                ORDER BY e.time_period_end\n",
    "            )\n",
    "\n",
    "            SELECT *\n",
    "            FROM total_eth_sent_per_hour\n",
    "            \"\"\"\n",
    "\n",
    "            # Execute query on Redshift and return result\n",
    "            cursor.execute(query)\n",
    "            tuples = cursor.fetchall()\n",
    "            \n",
    "            # Return queried data as a DataFrame\n",
    "            cols = ['Date', 'total_eth_send_per_hour']\n",
    "            df = pd.DataFrame(tuples, columns = cols).set_index('Date')\n",
    "            df = df.astype(float)\n",
    "\n",
    "            return df\n",
    "\n",
    "@njit\n",
    "def helper(i, df, tp, sl, max_hold_time):\n",
    "    if i - 1 < 0:\n",
    "        return np.nan\n",
    "    \n",
    "    hold_countdown = max_hold_time\n",
    "\n",
    "    for j in range(i, len(df)):\n",
    "        if hold_countdown == 0:\n",
    "            trade_return = (df[j] - df[i]) / df[i]\n",
    "            return 1 if np.sign(trade_return) > 0 else -1\n",
    "        \n",
    "        price = df[j]\n",
    "        price_prev = df[j - 1]\n",
    "        \n",
    "        if price_prev < tp and price > tp:\n",
    "            return 1\n",
    "        elif price_prev > sl and price < sl:\n",
    "            return -1\n",
    "        \n",
    "        hold_countdown -= 1\n",
    "\n",
    "    trade_return = (df[-1] - df[i]) / df[i]\n",
    "    return 1 if np.sign(trade_return) > 0 else -1\n",
    "\n",
    "@njit\n",
    "def triple_barrier(df, rolling_std, max_hold_time, std_multiple_tp, std_multiple_sl):\n",
    "    to_return = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        tp = df[i] + rolling_std[i] * std_multiple_tp\n",
    "        sl = df[i] - rolling_std[i] * std_multiple_sl\n",
    "\n",
    "        if not (tp != np.nan and sl != np.nan):\n",
    "            to_return.append(np.nan)\n",
    "        else:\n",
    "            to_return.append(helper(\n",
    "                i = i, \n",
    "                df = df,\n",
    "                tp = tp,\n",
    "                sl = sl,\n",
    "                max_hold_time = max_hold_time\n",
    "            ))\n",
    "\n",
    "    return to_return\n",
    "\n",
    "def rolling_mean(col, window):\n",
    "    return col.rolling(window).mean().rename({col.columns[0]:'rolling_mean_{}_{}'.format(col.columns[0], window)}, axis = 1)\n",
    "\n",
    "def rolling_var(col, window):\n",
    "    return col.rolling(window).var().rename({col.columns[0]:'rolling_var_{}_{}'.format(col.columns[0], window)}, axis = 1)\n",
    "\n",
    "def rolling_skew(col, window):\n",
    "    return col.rolling(window).skew().rename({col.columns[0]:'rolling_skew_{}_{}'.format(col.columns[0], window)}, axis = 1)\n",
    "\n",
    "def rolling_kurt(col, window):\n",
    "    return col.rolling(window).kurt().rename({col.columns[0]:'rolling_kurt_{}_{}'.format(col.columns[0], window)}, axis = 1)\n",
    "\n",
    "def rrsi(close, window):\n",
    "    return RSIIndicator(close = close, window = window, fillna = False).rsi().to_frame().rename({'rsi':'rsi_{}'.format(window)}, axis = 1)\n",
    "\n",
    "def rolling_z_score(col, window):\n",
    "    mean = col.rolling(window).mean().shift(1)\n",
    "    std = col.rolling(window).std().shift(1)\n",
    "    z = ((col - mean) / std).replace([np.inf, -np.inf], 0)\n",
    "\n",
    "    return z.rename({col.columns[0]:'rolling_z_{}_{}'.format(col.columns[0], window)}, axis = 1)\n",
    "\n",
    "def pca(X_train, X_test, n_components):\n",
    "    ss = StandardScaler()\n",
    "    pca = PCA(n_components = n_components)\n",
    "\n",
    "    X_train = ss.fit_transform(X_train)\n",
    "    X_test = ss.transform(X_test)\n",
    "\n",
    "    X_train = pca.fit_transform(X_train)\n",
    "    X_test = pca.transform(X_test)\n",
    "\n",
    "    return X_train, X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blockchain_metrics = fetch_blockchain_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rolling_mean_returns_6</th>\n",
       "      <th>rolling_var_returns_6</th>\n",
       "      <th>rolling_skew_returns_6</th>\n",
       "      <th>rolling_kurt_returns_6</th>\n",
       "      <th>rolling_mean_volume_returns_6</th>\n",
       "      <th>rolling_var_volume_returns_6</th>\n",
       "      <th>rolling_skew_volume_returns_6</th>\n",
       "      <th>rolling_kurt_volume_returns_6</th>\n",
       "      <th>rolling_z_price_close_6</th>\n",
       "      <th>rolling_z_volume_traded_6</th>\n",
       "      <th>...</th>\n",
       "      <th>rolling_z_volume_returns_24</th>\n",
       "      <th>price_close</th>\n",
       "      <th>volume_traded</th>\n",
       "      <th>returns</th>\n",
       "      <th>volume_returns</th>\n",
       "      <th>asset_id_base</th>\n",
       "      <th>asset_id_quote</th>\n",
       "      <th>exchange_id</th>\n",
       "      <th>triple_barrier_label</th>\n",
       "      <th>next_period_returns</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-07-17 06:00:00</th>\n",
       "      <td>0.004731</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>2.305993</td>\n",
       "      <td>5.391093</td>\n",
       "      <td>1.041900</td>\n",
       "      <td>5.474776</td>\n",
       "      <td>1.937555</td>\n",
       "      <td>4.054078</td>\n",
       "      <td>0.909418</td>\n",
       "      <td>2.021897</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.222343</td>\n",
       "      <td>31.713</td>\n",
       "      <td>2275.066293</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>1.297596</td>\n",
       "      <td>ZEC</td>\n",
       "      <td>USD</td>\n",
       "      <td>BITFINEX</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.282411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-17 07:00:00</th>\n",
       "      <td>0.005738</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>2.008165</td>\n",
       "      <td>4.189227</td>\n",
       "      <td>0.854559</td>\n",
       "      <td>6.042556</td>\n",
       "      <td>1.882246</td>\n",
       "      <td>3.677469</td>\n",
       "      <td>1.298609</td>\n",
       "      <td>-1.546832</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.322180</td>\n",
       "      <td>31.921</td>\n",
       "      <td>280.754136</td>\n",
       "      <td>0.006559</td>\n",
       "      <td>-0.876595</td>\n",
       "      <td>ZEC</td>\n",
       "      <td>USD</td>\n",
       "      <td>BITFINEX</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.021487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-17 08:00:00</th>\n",
       "      <td>0.002018</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1.172623</td>\n",
       "      <td>0.049511</td>\n",
       "      <td>1.178995</td>\n",
       "      <td>6.298315</td>\n",
       "      <td>1.244825</td>\n",
       "      <td>1.113579</td>\n",
       "      <td>1.614009</td>\n",
       "      <td>-0.317940</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.168516</td>\n",
       "      <td>31.909</td>\n",
       "      <td>931.697003</td>\n",
       "      <td>-0.000376</td>\n",
       "      <td>2.318551</td>\n",
       "      <td>ZEC</td>\n",
       "      <td>USD</td>\n",
       "      <td>BITFINEX</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.099362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-17 09:00:00</th>\n",
       "      <td>0.002383</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.856427</td>\n",
       "      <td>-0.069330</td>\n",
       "      <td>1.341338</td>\n",
       "      <td>5.659718</td>\n",
       "      <td>1.316851</td>\n",
       "      <td>1.579071</td>\n",
       "      <td>1.635107</td>\n",
       "      <td>-0.024568</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.272092</td>\n",
       "      <td>31.985</td>\n",
       "      <td>1032.491705</td>\n",
       "      <td>0.002382</td>\n",
       "      <td>0.108184</td>\n",
       "      <td>ZEC</td>\n",
       "      <td>USD</td>\n",
       "      <td>BITFINEX</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.058616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-17 10:00:00</th>\n",
       "      <td>-0.002306</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>-2.164378</td>\n",
       "      <td>5.068198</td>\n",
       "      <td>0.267542</td>\n",
       "      <td>1.660161</td>\n",
       "      <td>0.911326</td>\n",
       "      <td>-0.572529</td>\n",
       "      <td>-4.289092</td>\n",
       "      <td>-1.540821</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.321302</td>\n",
       "      <td>31.216</td>\n",
       "      <td>139.391736</td>\n",
       "      <td>-0.024043</td>\n",
       "      <td>-0.864995</td>\n",
       "      <td>ZEC</td>\n",
       "      <td>USD</td>\n",
       "      <td>BITFINEX</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.072199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     rolling_mean_returns_6  rolling_var_returns_6  \\\n",
       "Date                                                                 \n",
       "2023-07-17 06:00:00                0.004731               0.000073   \n",
       "2023-07-17 07:00:00                0.005738               0.000069   \n",
       "2023-07-17 08:00:00                0.002018               0.000007   \n",
       "2023-07-17 09:00:00                0.002383               0.000007   \n",
       "2023-07-17 10:00:00               -0.002306               0.000119   \n",
       "\n",
       "                     rolling_skew_returns_6  rolling_kurt_returns_6  \\\n",
       "Date                                                                  \n",
       "2023-07-17 06:00:00                2.305993                5.391093   \n",
       "2023-07-17 07:00:00                2.008165                4.189227   \n",
       "2023-07-17 08:00:00                1.172623                0.049511   \n",
       "2023-07-17 09:00:00                0.856427               -0.069330   \n",
       "2023-07-17 10:00:00               -2.164378                5.068198   \n",
       "\n",
       "                     rolling_mean_volume_returns_6  \\\n",
       "Date                                                 \n",
       "2023-07-17 06:00:00                       1.041900   \n",
       "2023-07-17 07:00:00                       0.854559   \n",
       "2023-07-17 08:00:00                       1.178995   \n",
       "2023-07-17 09:00:00                       1.341338   \n",
       "2023-07-17 10:00:00                       0.267542   \n",
       "\n",
       "                     rolling_var_volume_returns_6  \\\n",
       "Date                                                \n",
       "2023-07-17 06:00:00                      5.474776   \n",
       "2023-07-17 07:00:00                      6.042556   \n",
       "2023-07-17 08:00:00                      6.298315   \n",
       "2023-07-17 09:00:00                      5.659718   \n",
       "2023-07-17 10:00:00                      1.660161   \n",
       "\n",
       "                     rolling_skew_volume_returns_6  \\\n",
       "Date                                                 \n",
       "2023-07-17 06:00:00                       1.937555   \n",
       "2023-07-17 07:00:00                       1.882246   \n",
       "2023-07-17 08:00:00                       1.244825   \n",
       "2023-07-17 09:00:00                       1.316851   \n",
       "2023-07-17 10:00:00                       0.911326   \n",
       "\n",
       "                     rolling_kurt_volume_returns_6  rolling_z_price_close_6  \\\n",
       "Date                                                                          \n",
       "2023-07-17 06:00:00                       4.054078                 0.909418   \n",
       "2023-07-17 07:00:00                       3.677469                 1.298609   \n",
       "2023-07-17 08:00:00                       1.113579                 1.614009   \n",
       "2023-07-17 09:00:00                       1.579071                 1.635107   \n",
       "2023-07-17 10:00:00                      -0.572529                -4.289092   \n",
       "\n",
       "                     rolling_z_volume_traded_6  ...  \\\n",
       "Date                                            ...   \n",
       "2023-07-17 06:00:00                   2.021897  ...   \n",
       "2023-07-17 07:00:00                  -1.546832  ...   \n",
       "2023-07-17 08:00:00                  -0.317940  ...   \n",
       "2023-07-17 09:00:00                  -0.024568  ...   \n",
       "2023-07-17 10:00:00                  -1.540821  ...   \n",
       "\n",
       "                     rolling_z_volume_returns_24  price_close  volume_traded  \\\n",
       "Date                                                                           \n",
       "2023-07-17 06:00:00                    -0.222343       31.713    2275.066293   \n",
       "2023-07-17 07:00:00                    -0.322180       31.921     280.754136   \n",
       "2023-07-17 08:00:00                    -0.168516       31.909     931.697003   \n",
       "2023-07-17 09:00:00                    -0.272092       31.985    1032.491705   \n",
       "2023-07-17 10:00:00                    -0.321302       31.216     139.391736   \n",
       "\n",
       "                      returns  volume_returns  asset_id_base  asset_id_quote  \\\n",
       "Date                                                                           \n",
       "2023-07-17 06:00:00  0.000536        1.297596            ZEC             USD   \n",
       "2023-07-17 07:00:00  0.006559       -0.876595            ZEC             USD   \n",
       "2023-07-17 08:00:00 -0.000376        2.318551            ZEC             USD   \n",
       "2023-07-17 09:00:00  0.002382        0.108184            ZEC             USD   \n",
       "2023-07-17 10:00:00 -0.024043       -0.864995            ZEC             USD   \n",
       "\n",
       "                     exchange_id  triple_barrier_label  next_period_returns  \n",
       "Date                                                                         \n",
       "2023-07-17 06:00:00     BITFINEX                  -1.0             0.282411  \n",
       "2023-07-17 07:00:00     BITFINEX                  -1.0            -0.021487  \n",
       "2023-07-17 08:00:00     BITFINEX                  -1.0             0.099362  \n",
       "2023-07-17 09:00:00     BITFINEX                  -1.0            -1.058616  \n",
       "2023-07-17 10:00:00     BITFINEX                   1.0             0.072199  \n",
       "\n",
       "[5 rows x 117 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "triple_barrier_labels = np.array([])\n",
    "returns_data = np.array([])\n",
    "\n",
    "window = 24\n",
    "\n",
    "for token in get_unique_tokens().to_dict(orient = 'records'):\n",
    "    if token['asset_id_base'] in ['USD', 'USDT', 'USDC']:\n",
    "        continue\n",
    "\n",
    "    price_data = fetch_OHLCV_df_from_redshift(token['asset_id_base'], token['asset_id_quote'], token['exchange_id'])\n",
    "    # price_data = price_data.merge(blockchain_metrics, left_index = True, right_index = True, how = 'inner')\n",
    "    price_data['volume_traded'] = price_data['volume_traded'] * price_data['price_close']\n",
    "    \n",
    "    rolling_std = price_data.price_close.rolling(window).std().values\n",
    "\n",
    "    triple_barrier_label = triple_barrier(\n",
    "        df = price_data.price_close.values,\n",
    "        rolling_std = rolling_std,\n",
    "        max_hold_time = 24,\n",
    "        std_multiple_tp = 2,\n",
    "        std_multiple_sl = 2\n",
    "    )\n",
    "\n",
    "    returns = price_data[['price_close']].pct_change().rename({'price_close':'returns'}, axis = 1)\n",
    "    volume = price_data[['volume_traded']].pct_change().rename({'volume_traded':'volume_returns'}, axis = 1)\n",
    "    # eth_sent = price_data[['total_eth_send_per_hour']].pct_change().rename({'total_eth_send_per_hour':'total_eth_sent_returns'}, axis = 1)\n",
    "\n",
    "    price_data_w_features = []\n",
    "\n",
    "    for i in range(6, 24 + 1, 6):\n",
    "        rm_price = rolling_mean(returns, i)\n",
    "        rv_price = rolling_var(returns, i)\n",
    "        rs_price = rolling_skew(returns, i)\n",
    "        rk_price = rolling_kurt(returns, i)\n",
    "\n",
    "        rm_volume = rolling_mean(volume, i)\n",
    "        rv_volume = rolling_var(volume, i)\n",
    "        rs_volume = rolling_skew(volume, i)\n",
    "        rk_volume = rolling_kurt(volume, i)\n",
    "\n",
    "        # rm_total_eth_sent = rolling_mean(eth_sent, i)\n",
    "        # rv_total_eth_sent = rolling_var(eth_sent, i)\n",
    "        # rs_total_eth_sent = rolling_skew(eth_sent, i)\n",
    "        # rk_total_eth_sent = rolling_kurt(eth_sent, i)\n",
    "\n",
    "        rz_price = rolling_z_score(price_data[['price_close']], i)\n",
    "        rz_volume = rolling_z_score(price_data[['volume_traded']], i)\n",
    "        # rz_eth_sent = rolling_z_score(price_data[['total_eth_send_per_hour']], i)\n",
    "        # rz_eth_sent_returns = rolling_z_score(eth_sent, i)\n",
    "        rz_returns = rolling_z_score(returns, i)\n",
    "        rz_volume_returns = rolling_z_score(volume, i)\n",
    "\n",
    "        to_comb = [\n",
    "            rm_price, rv_price, rs_price, rk_price,\n",
    "            rm_volume, rv_volume, rs_volume, rk_volume,\n",
    "            # rm_total_eth_sent, rv_total_eth_sent, rs_total_eth_sent, rk_total_eth_sent,\n",
    "            rz_price, rz_volume, rz_returns, rz_volume_returns, # rz_eth_sent, rz_eth_sent_returns,\n",
    "            price_data[['price_close']], price_data[['volume_traded']], returns, volume\n",
    "        ]\n",
    "\n",
    "        comb = pd.concat(to_comb, axis = 1)\n",
    "        price_data_w_features.append(comb)\n",
    "\n",
    "    price_data_w_features = pd.concat(price_data_w_features, axis = 1)\n",
    "    price_data_w_features['asset_id_base'] = token['asset_id_base']\n",
    "    price_data_w_features['asset_id_quote'] = token['asset_id_quote']\n",
    "    price_data_w_features['exchange_id'] = token['exchange_id']\n",
    "    \n",
    "    data.append(price_data_w_features)\n",
    "    triple_barrier_labels = np.append(triple_barrier_labels, triple_barrier_label)\n",
    "    returns_data = np.append(\n",
    "        returns_data, \n",
    "        ((returns - returns.mean()) / returns.std()).shift(-1).values.tolist()\n",
    "    )\n",
    "\n",
    "data = pd.concat(data)\n",
    "triple_barrier_labels = np.ravel(triple_barrier_labels)\n",
    "returns = np.ravel(returns_data)\n",
    "\n",
    "data['triple_barrier_label'] = triple_barrier_labels\n",
    "data['next_period_returns'] = returns\n",
    "\n",
    "data = data.dropna()\n",
    "\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_training_data = 0.7\n",
    "train_cutoff = int(len(data) * pct_training_data)\n",
    "\n",
    "features = pd.get_dummies(data.drop(['triple_barrier_label', 'next_period_returns'], axis = 1))\n",
    "\n",
    "X_train = features.iloc[:train_cutoff]\n",
    "y_train = data['triple_barrier_label'].iloc[:train_cutoff]\n",
    "\n",
    "X_test = features.iloc[train_cutoff:]\n",
    "y_test = data['triple_barrier_label'].iloc[train_cutoff:]\n",
    "\n",
    "X_train, X_test = pca(X_train, X_test, 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_training_data = 0.7\n",
    "train_cutoff = int(len(data) * pct_training_data)\n",
    "\n",
    "features = pd.get_dummies(data.drop(['triple_barrier_label', 'next_period_returns'], axis = 1))\n",
    "\n",
    "X_train = features.iloc[:train_cutoff]\n",
    "y_train = data['next_period_returns'].iloc[:train_cutoff]\n",
    "\n",
    "X_test = features.iloc[train_cutoff:]\n",
    "y_test = data['next_period_returns'].iloc[train_cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Regression Report:\n",
      "\n",
      "RMSE:  1.0021127971479917\n",
      "R2:  -1.3207889848043664e-05\n",
      "\n",
      "Test Data Classification Report:\n",
      "\n",
      "RMSE:  0.9633873313272675\n",
      "R2:  -1.3238382587932307e-06\n"
     ]
    }
   ],
   "source": [
    "lin = LinearRegression()\n",
    "lin.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = lin.predict(X_train)\n",
    "y_test_pred = lin.predict(X_test)\n",
    "\n",
    "print('Training Data Regression Report:')\n",
    "print()\n",
    "print('RMSE: ', np.sqrt(mean_squared_error(y_train, y_train_pred)))\n",
    "print('R2: ', r2_score(y_train, y_train_pred))\n",
    "print()\n",
    "print('Test Data Classification Report:')\n",
    "print()\n",
    "print('RMSE: ', np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "print('R2: ', r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators = 2, criterion = 'absolute_error')\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = rf.predict(X_train)\n",
    "y_test_pred = rf.predict(X_test)\n",
    "\n",
    "print('Training Data Regression Report:')\n",
    "print()\n",
    "print('RMSE: ', np.sqrt(mean_squared_error(y_train, y_train_pred)))\n",
    "print('R2: ', r2_score(y_train, y_train_pred))\n",
    "print()\n",
    "print('Test Data Classification Report:')\n",
    "print()\n",
    "print('RMSE: ', np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "print('R2: ', r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin = GradientBoostingRegressor(n_estimators = 2, loss = 'absolute_error')\n",
    "lin.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = lin.predict(X_train)\n",
    "y_test_pred = lin.predict(X_test)\n",
    "\n",
    "print('Training Data Regression Report:')\n",
    "print()\n",
    "print('RMSE: ', np.sqrt(mean_squared_error(y_train, y_train_pred)))\n",
    "print('R2: ', r2_score(y_train, y_train_pred))\n",
    "print()\n",
    "print('Test Data Classification Report:')\n",
    "print()\n",
    "print('RMSE: ', np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "print('R2: ', r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Regression Report:\n",
      "\n",
      "MSE:  1.004230058207772\n",
      "R2:  -1.3207889848043664e-05\n",
      "\n",
      "Test Data Classification Report:\n",
      "\n",
      "MSE:  0.9281151501618744\n",
      "R2:  -1.3238382587932307e-06\n"
     ]
    }
   ],
   "source": [
    "clf = MLPRegressor(hidden_layer_sizes=(1000,1000,1000), max_iter = 5)\n",
    "lin.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = lin.predict(X_train)\n",
    "y_test_pred = lin.predict(X_test)\n",
    "\n",
    "print('Training Data Regression Report:')\n",
    "print()\n",
    "print('MSE: ', mean_squared_error(y_train, y_train_pred))\n",
    "print('R2: ', r2_score(y_train, y_train_pred))\n",
    "print()\n",
    "print('Test Data Classification Report:')\n",
    "print()\n",
    "print('MSE: ', mean_squared_error(y_test, y_test_pred))\n",
    "print('R2: ', r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = LogisticRegression(max_iter = 100, solver='saga', penalty = 'l1')\n",
    "log.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = log.predict(X_train)\n",
    "y_test_pred = log.predict(X_test)\n",
    "\n",
    "print('Training Data Classification Report:')\n",
    "print()\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "print()\n",
    "print('Test Data Classification Report:')\n",
    "print()\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = rf.predict(X_train)\n",
    "y_test_pred = rf.predict(X_test)\n",
    "\n",
    "print('Training Data Classification Report:')\n",
    "print()\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "print()\n",
    "print('Test Data Classification Report:')\n",
    "print()\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = gb.predict(X_train)\n",
    "y_test_pred = gb.predict(X_test)\n",
    "\n",
    "print('Training Data Classification Report:')\n",
    "print()\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "print()\n",
    "print('Test Data Classification Report:')\n",
    "print()\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(100,100), max_iter = 100)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "print('Training Data Classification Report:')\n",
    "print()\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "print()\n",
    "print('Test Data Classification Report:')\n",
    "print()\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
